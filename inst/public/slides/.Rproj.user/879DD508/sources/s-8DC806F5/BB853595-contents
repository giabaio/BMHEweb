---
title: "&#8291;11. Introduction to Value of Information"
author: Gianluca Baio
institute: "[Department of Statistical Science](https://www.ucl.ac.uk/statistics/) | University College London"
params: 
   - conference: "Bayesian Methods in Health Economics"
   - location: "Lausanne"
date: 
output:
  xaringan::moon_reader:
    includes: 
       in_header: "../assets/latex_macros.html" 
       ## This line adds a logo based on the format selected in the file 'assets/THEME/include_logo.html'
       ## NB: the actual options (eg placement of the logo and actual logo file) can be changed there
       ## There's also a script to manipulate the colouring scheme for the UCL logo (from a basic black/white one)
       after_body: "../assets/beamer/insert-logo-ucl.html"
    seal: false
    yolo: no
    lib_dir: libs
    nature:
      beforeInit: ["https://platform.twitter.com/widgets.js"]
      highlightStyle: github
      highlightLines: yes
      highlightSpans: true
      countIncrementalSlides: no
      ratio: '16:9'
      titleSlideClass:
      - center
      - middle
    self_contained: false 
    css:
    - "../assets/beamer.css"
---

```{r echo=F,message=FALSE,warning=FALSE,comment=NA}
# Sources the R file with all the relevant setup and commands
source("../assets/setup.R")

# Stuff from 'xaringanExtra' (https://pkg.garrickadenbuie.com/xaringanExtra)
# This allows the use of panels (from 'xaringanExtra')
xaringanExtra::use_panelset()
# This allows to copy code from the slides directly
xaringanExtra::use_clipboard()
# This freezes the frame for when there's a gif included
xaringanExtra::use_freezeframe()

# Defines the path to the file with the .bib entries (in case there are references)
bibfile=ReadBib("~/Dropbox/Perso/Office/CV/mypubs.bib",check = FALSE)

```

```{r title-page, child="../assets/title-slide-gb.Rmd"}
```

# Summary

- Motivating Value of Information (VoI) approach

- Summarising uncertainty and PSA

- Research priorities

`r vspace("4em")`

.content-box-beamer[
### **References** 

`r vspace("20px")`

`r bmhe(c("3.5.2","3.5.3"))`

`r esdm(12)`

`r bcea_book(4.3)` 

]

---

# Knowledge is power?

## (A tale of two stupid examples)

```{css echo=FALSE}
.left-column30 {
  width: 30%;
  height: 92%;
  float: left;
}
.left-column30 h2, .left-column h3 {
  color: #035AA699;
}
.left-column30 h2:last-of-type, .left-column h3:last-child {
  color: #035AA6;
}
.right-column70 {
  width: 65%;
  float: right;
  padding-top: 0em;
}
```

.left-column30[
`r include_fig("knowledge_power.jpg",width="75%")`
]

.right-columnt70[

- **Example 1**: Intervention $t=1$ is more cost-effective, given current evidence
   - $\class{myblue}{\Pr(t=1 `r sftext(" is cost-effective")`) = `r sftext("0.51")`}$
   - If we get it wrong: 
      - Increase in population average costs $=$ £3
      - Decrease in population average effectiveness $=$ 0.000001 QALYs
   - .red[Large uncertainty]/.traffic-light-green[negligible consequences] $\Rightarrow$ .traffic-light-green[**can afford uncertainty**!]

]

---

count: false
# Value of Information (VoI)

## (A tale of two stupid examples)

.left-column30[
`r include_fig("knowledge_power.jpg",width="75%")`
]

.right-columnt70[

- **Example 1**: Intervention $t=1$ is more cost-effective, given current evidence
   - $\class{myblue}{\Pr(t=1 `r sftext(" is cost-effective")`) = `r sftext("0.51")`}$
   - If we get it wrong: 
      - Increase in population average costs $=$ £3
      - Decrease in population average effectiveness $=$ 0.000001 QALYs
   - .red[Large uncertainty]/.traffic-light-green[negligible consequences] $\Rightarrow$ .traffic-light-green[**can afford uncertainty**!]

`r vspace("60px")`
- **Example 2**: Intervention $t=1$ is more cost-effective, given current evidence
   - $\class{myblue}{\Pr(t=1 `r sftext(" is cost-effective")`) = `r sftext("0.999")`}$
   - If we get it wrong: 
      - Increase in population average costs $=$ £1000000000
      - Decrease in population average effectiveness $=$ 999999 QALYs
   - .traffic-light-green[Tiny uncertainty]/.red[dire consequences] $\Rightarrow$ .traffic-light-amber[**probably should think about it...**!]

]

---

# Decisions with uncertainty

- Net Benefit depends on:

   - Relative treatment efficacy (e.g. meta-analysis)
   
   - Relative treatment efficacy (e.g. meta-analy Natural history / disease progression
   
   - Utility (quality of life)
   
   - Economic parameters (costs)


- Uncertainty may exist on all these inputs

   - *Parameter* uncertainty
   

- Translates into uncertainty in expected NB

   - *Decision* uncertainty
   
   - Are we happy to make a decision currently?
   
   - Should we consider collecting more info?


---

# Evidence based decision-making and VoI

`r include_fig("evi_process.png",width="75%")`

--

.blue[**Process inherently Bayesian!**]


`r vspace("-5px")`
.small[Slide stolen from [Nicky Welton](https://www.bristol.ac.uk/people/person/Nicky-Welton-9c4cd60d-0c6d-42b3-af4f-a1006a4e46ee/)]

---

# VoI: Basic ideas

- A new study will provide more data
   - Reducing (or even eliminating?...) uncertainty in a subset of the model parameters
   
- Update the cost-effectiveness model
   - If optimal decision changes, gain in monetary **.blue[net benefit]** (NB = utility) from using new optimal treatment
   - If optimal decision doesn't change, no gain in NB
   
- .red[**Expected**] VoI is the average gain in NB

---

count: false
# VoI: Basic ideas & relevant measures

- A new study will provide more data
   - Reducing (or even eliminating?...) uncertainty in a subset of the model parameters
   
- Update the cost-effectiveness model
   - If optimal decision changes, gain in monetary net benefit (NB = utility) from using new optimal treatment
   - If optimal decision doesn't change, no gain in NB
   
- .red[**Expected**] VoI is the average gain in NB

`r vspace("-10px")`

1. **Expected value of Perfect Information** (EVPI)    
   - Value of completely resolving uncertainty in all input parameters to decision model 
   - Infinite-sized, long-term follow up trial measuring everything!...
   - Gives an upper bound on the value of the new study &ndash; low EVPI suggests we can make our decision based on existing information
   
---

count: false
# VoI: Basic ideas & relevant measures

- A new study will provide more data
   - Reducing (or even eliminating?...) uncertainty in a subset of the model parameters
   
- Update the cost-effectiveness model
   - If optimal decision changes, gain in monetary net benefit (NB = utility) from using new optimal treatment
   - If optimal decision doesn't change, no gain in NB
   
- .red[**Expected**] VoI is the average gain in NB

`r vspace("-10px")`

1. **Expected value of Perfect Information** (EVPI)    
   - Value of completely resolving uncertainty in all input parameters to decision model 
   - Infinite-sized, long-term follow up trial measuring everything!...
   - Gives an upper bound on the value of the new study &ndash; low EVPI suggests we can make our decision based on existing information
2. **Expected value of Partial Perfect Information** (EVPPI)     
   - Value of eliminating uncertainty in subset of input parameters to decision model
   - e.g.: Infinite-sized trial measuring relative effects on 1-year survival
   - Useful to identify which parameters are responsible for decision uncertainty
---

count: false
# VoI: Basic ideas & relevant measures

- A new study will provide more data
   - Reducing (or even eliminating?...) uncertainty in a subset of the model parameters
   
- Update the cost-effectiveness model
   - If optimal decision changes, gain in monetary net benefit (NB = utility) from using new optimal treatment
   - If optimal decision doesn't change, no gain in NB
   
- .red[**Expected**] VoI is the average gain in NB

`r vspace("-10px")`

1. **Expected value of Perfect Information** (EVPI)    
   - Value of completely resolving uncertainty in all input parameters to decision model 
   - Infinite-sized, long-term follow up trial measuring everything!...
   - Gives an upper bound on the value of the new study &ndash; low EVPI suggests we can make our decision based on existing information
2. **Expected value of Partial Perfect Information** (EVPPI)    
   - Value of eliminating uncertainty in subset of input parameters to decision model
   - e.g.: Infinite-sized trial measuring relative effects on 1-year survival
   - Useful to identify which parameters are responsible for decision uncertainty
3. **Expected value of Sample Information** (EVSI)    
   - Value of reducing uncertainty by conducting a specific study of a given design
   - Can compare the benefits and costs of a study with given design
   - Is the proposed study likely to be a good use of resource? What is the optimal design?

---

count: false
# VoI: Basic ideas & relevant measures

`r icon::icon_style(icon::fontawesome("info-circle"),scale=1.7,fill="#035AA6",top=".45em")`  In general, VoI measures are always expressed as something like

`r vspace("40px")`
.center[
.content-box-gray[

.olive[**VoI measure**] $=$ .blue[**Some idealised decision-making process**] $-$ .magenta[**current decision-making process**]
]
]

--

`r vspace("40px")`

## Complexity

- There's no natural upper bound
   - Voi measures are positive, but *how low is low?*...
   
- Need to account for other factors
   - How much would it cost to get to the point when we can make the idealised decision-making process?
   - Who would that affect?
   - For how long?
   - ...
   
- Computational & modelling issues
   - You need to know what you're doing (again, modelling **fundamentally** Bayesian)
   - And use suitable tools (basically, never use spreadsheets...)

---

exclude: false
# Summarising uncertainty analysis (PSA)

## Expected Value of Perfect Information

.alignleft[
```{r echo=FALSE}
library(kableExtra)
options(knitr.kable.NA = "\\(\\ldots\\)")
set.seed(140873)
nb0=9685*round(rnorm(10000,7.5,3))
nb1=9685*round(rnorm(10000,8,3))
mnb=pmax(nb1,nb0)
ol=mnb-nb1
show.col=4
tab=tibble(
   iter=c(format(seq(1,show.col),digits=1),NA,format(1000,digits=1)),
   pi0=c(format(rbeta(show.col,1,2),digits=3,nsmall=0),NA,format(rbeta(1,1,2),digits=3,nsmall=0)),
   rho=c(format(rbeta(show.col,1,2),digits=3,nsmall=0),NA,format(rbeta(1,1,2),digits=3,nsmall=0)),
   dots=rep("\\(\\ldots\\)",show.col+2),
   gamma=c(format(rbeta(show.col,1,2),digits=3,nsmall=0),NA,format(rbeta(1,1,2),digits=3,nsmall=0)),
   nb0=c(nb0[1:show.col],NA,nb0[10000]),
   nb1=c(nb1[1:show.col],NA,nb1[10000])
)
tab=tab %>% mutate(
   mnb=c(mnb[1:show.col],NA,mnb[10000]),
   ol=c(ol[1:show.col],NA,ol[10000])
)

tab[1:5] %>% kable(col.names=c(
   "Iteration","\\(\\pi_0\\)","\\(\\rho\\)","\\(\\ldots\\)","\\(\\gamma\\)"
   ##"\\(\\nb_0(\\boldsymbol\\theta)\\)","\\(\\nb_1(\\boldsymbol\\theta)\\)","Maximum net benefit","Opportunity loss"
   ), align="c"
   ) %>% kable_classic() %>%
   column_spec(1:5,width="2cm") %>% 
   #column_spec(c(8,9), width = "120px") %>% 
   kable_styling(full_width=T) %>% 
   # add_header_above(c(" "=1,"Parameter simulations"=4,"Expected utility"=2," "=2)) %>% 
   add_header_above(c(" "=1,"Parameter simulations"=4)) %>% 
   row_spec(nrow(tab),extra_css="border-bottom: 2px solid;") 

```
]

`r vspace("9.5cm")`
- Characterise uncertainty in the model parameters
   - In a full Bayesian setting, these are drawings from the posterior distribution of $\boldsymbol\theta$
   - In a frequentist setting, these are typically bootstrap draws from a set of univariate ditributions that describe some level of uncertainty around the MLEs

---

exclude: false
count: false
# Summarising uncertainty analysis (PSA)

## Expected Value of Perfect Information

.alignleft[
```{r echo=FALSE}
tab2=tab %>% add_row(
   iter="",
   pi0="",
   rho="",
   dots="",
   gamma="Average",
   nb0=mean(nb0),
   nb1=mean(nb1),
   mnb=mean(mnb,na.rm=T),
   ol=mean(ol,na.rm=T)
)

italics1=tab$nb1>tab$nb0; italics1[is.na(italics1)]=FALSE
italics0=tab$nb0>tab$nb1; italics0[is.na(italics0)]=FALSE
tab2[1:7] %>% kable(col.names=c(
   "Iteration","\\(\\pi_0\\)","\\(\\rho\\)","\\(\\ldots\\)","\\(\\gamma\\)",
   "\\(\\nb_0(\\boldsymbol\\theta)\\)","\\(\\nb_1(\\boldsymbol\\theta)\\)"
   #,"Maximum net benefit","Opportunity loss"
   ), align="c"
   ) %>% kable_classic() %>%
   column_spec(1:5,width="2cm") %>% 
   #column_spec(c(8,9), width = "120px") %>% 
   kable_styling(full_width=T) %>% 
   # add_header_above(c(" "=1,"Parameter simulations"=4,"Expected utility"=2," "=2)) %>% 
   add_header_above(c(" "=1,"Parameter simulations"=4,"Expected utility"=2)) %>% 
   row_spec(nrow(tab2),extra_css="border-bottom: 2px black solid;") %>% 
   row_spec(nrow(tab2)-1,extra_css="border-bottom: 2px black solid;") %>% 
   column_spec(7,color=c(rep("black",(nrow(tab))),"magenta"),italic=c(italics1,TRUE),width="2cm") %>% 
   column_spec(6,italic=c(italics0,FALSE),width="2cm")

```
]

`r vspace("9.5cm")`
- Uncertainty in the parameters induces a distribution of decisions
   - Typically based on the **net benefits**: $\class{myblue}{\nb_t(\boldsymbol\theta)=k\mu_{et}-\mu_{ct}}$
   - In each parameter configuration can identify the *optimal strategy*
   
- Averaging over the uncertainty in $\boldsymbol\theta$ provides $t^*$, the overall optimal decision *given current uncertainty* (= choose the intervention associated with .magenta[*highest* **expected utility**])

---

exclude: false
count: false
# Summarising uncertainty analysis (PSA)

## Expected Value of Perfect Information

.alignleft[
```{r echo=FALSE}
tab2 %>% kable(col.names=c(
   "Iteration","\\(\\pi_0\\)","\\(\\rho\\)","\\(\\ldots\\)","\\(\\gamma\\)",
   "\\(\\nb_0(\\boldsymbol\\theta)\\)","\\(\\nb_1(\\boldsymbol\\theta)\\)",
   "Maximum net benefit","Opportunity loss"), align="c"
   ) %>% kable_classic() %>%
   column_spec(1:5,width="2cm") %>% 
#   column_spec(c(8,9), width = "120px") %>% 
   kable_styling(full_width=T) %>% 
   add_header_above(c(" "=1,"Parameter simulations"=4,"Expected utility"=2," "=2)) %>% 
   row_spec(nrow(tab2),extra_css="border-bottom: 2px black solid;") %>% 
   row_spec(nrow(tab2)-1,extra_css="border-bottom: 2px black solid;") %>% 
   column_spec(7,color=c(rep("black",(nrow(tab))),"magenta"),italic=c(italics1,TRUE),width="2cm") %>% 
   column_spec(6,italic=c(italics0,FALSE),width="2cm") %>% 
   column_spec(8,bold=c(rep(FALSE,nrow(tab)),TRUE),color=c(rep("black",nrow(tab)),"blue")) %>% 
   column_spec(9,color=c(rep("black",nrow(tab)),"olive"),bold=c(rep(FALSE,nrow(tab)),TRUE))

```
]

`r vspace("9.5cm")`
- **Expected value of "Perfect" Information** (EVPI) summarises uncertainty in the decision
   - Defined as the .olive[**average Opportunity Loss**], or .blue[**average maximum expected utility under "perfect" information**] $-$ .magenta[**maximum expected utility overall**]:
   `r vspace("-20px")`
   $$\class{olive}{\evpi} = \class{blue}{\E_\boldsymbol{\theta}\left[\max_t \nb_t(\boldsymbol\theta) \right]} - \class{magenta}{\max_t \E_\boldsymbol\theta \left[\nb_t(\boldsymbol\theta)\right]}$$

---

count: false
# Summarising uncertainty analysis (PSA)

## Expected Value of Perfect Information

\begin{align}
\class{myblue}{\evpi = \E_{\bm\theta}\left[ \max_t \nb_t(\bm\theta) \right] - \max_t \E_\bm\theta \left[\nb_t(\bm\theta)\right]}
\end{align}

- $\class{myblue}{\left[\max_t \nb_t(\bm\theta)\right]}$: Value of decision if we knew $\bm\theta$
- $\class{myblue}{\max_t \E_\bm\theta \left[\nb_t(\bm\theta)\right]}$: Value of decision based on current information

`r vspace("30pt")`

--

## Useful to rewrite as

\begin{align}
\class{myblue}{\evpi = \E_\bm\theta \left[\max_t\nb_t(\bm\theta) - \nb_{t*}(\bm\theta) \right]}
\end{align}
where $t^*$ maximises $\E_\bm\theta\left[\nb_t(\bm\theta)\right]$, based on current information

- $\class{myblue}{\left[\max_t\nb_t(\bm\theta) - \nb_{t*}(\bm\theta)\right]}$: Opportunity lost from using $t^*$ instead of the optimal $t$ for $\bm\theta$

--

.content-box-beamer[
### Golden rule of Value of Information

Information only has value if it changes your decision
]


---

exclude: false
count: false
# Summarising uncertainty analysis (PSA)

```{r echo=FALSE,opts=list(width="53%")}
library(BCEA)
data(Vaccine)
evi.plot(bcea(e,c,ref=2))
```

---

# Example &ndash; HIV screening decision model

## Objectives

- To investigate the net benefit of a universal screening over targeted screening for HIV

## Design of the study

- Multi-parameter evidence synthesis of observational studies

.footnote[Ades et al (2002) [Medical Decision Making](https://journals.sagepub.com/doi/abs/10.1177/0272989X0202200414)]

---

# Targeted prenatal screening

`r include_fig("targeted.png",width="65%")`

---

# Universal vs Targeted testing

`r include_fig("universal-vs-targeted.png",width="85%")`

`r vspace("-20pt")`
\begin{align}
\class{myblue}{\nb(\bm\theta) = \left\{ \begin{array}{ll} 0 & t=1, \text{targeted} \\ N(1-a-b)[e(1-h)(M-T)-T(1-e)] & t=2, \text{universal} \end{array} \right.}
\end{align}

- $N$ = number of pregnancies per year
- $(1-a-b)$ = proportion of "Low Risk"
- $M$ = net benefit of early maternal diagnosis
- $e$ = HIV prevalence in "Low Risk"
- $h$ = proportion of infected "Low Risk" already diagnosed
- $T$ = cost of screening test (= £3)

---

# Example &ndash; HIV screening decision model

`r vspace("-10pt")`

### Uncertainty in model inputs

\begin{align}
\class{myblue}{\bm\theta = \left\{ \begin{array}{ll} N,M,T & \text{economic parameters} \\ a,b,e,h & \text{epidemiological parameters} \end{array} \right.}
\end{align}

- $N$ = 105,000 
- $T$ = £3
- $M$ is uncertain
   - From previous model: $M$ = 600,012 - $\5\4,\2\9\6 Y$ with $Y \sim \dgamma(0.56, 3)I(0,2)$
   
- Epidemiology parameters estimated from multi-parameter evidence synthesis
   - Correlated
   - MCMC samples available

--

### Population EVPI

- NB is typically computed per individual patient

   - Need to multiple EVPI by the number of individuals expected to benefit per year
   
   - In HIV example population size included in NB, so already accounted for
   
- Also, expect the benefits of getting decision right to accrue for longer than 1 year

   - Until superseded...
   
   - In HIV example assume 10-year life-span of screening format (discounted to give a 7.7217 multiplier)

---

count: false
# Example &ndash; HIV screening decision model

## `R` code: Cost effectiveness analysis for the HIV example

```{r eval=FALSE}
# Read in 150,000 simulated values of M, a, b, e, h
par <- read.table("hiv150.txt",header=TRUE)
N <- 105000; T <- 3; Nsim <- nrow(par);
Nt <- 2                                # Nt=no. trts

# Net Benefit based on current information
NB <- matrix(rep(0,Nsim*Nt),Nsim,Nt)
NB[,2] <- N*(1-par$a-par$b)*(par$M*par$e*(1-par$h) - T*(1-par$e*par$h))
ENB <- apply(NB,2,mean)                # Column means for each trt
tstar <- which.max(ENB)                # t* optimises ENB

# Prob t* is cost-effective: checks if t=2 is optimal
CE <- ifelse(NB[,2]>NB[,1],1,0)
probCE <- mean(CE)                     # Prob t*=2 is cost-effective

# Find maximum NB for each simulation (ie max across rows of NB)
max.NBgain <- apply(NB,1,max) - NB[,tstar]

# Compute EVPI
EVPI <- 7.7217*mean(max.NBgain)
```

---

# Results

.pull-left[
`r include_fig("hiv-results1.png",width="120%")`
]

.pull-right[
`r vspace("30pt")`
- $\E(\ib) =$ £1,023,931 Universal vs Targeted

- Optimal decision $t^∗ =$ 2: Universal

- $\Pr(t^∗ = 2 `r sftext(" is optimal")`) = 0.971$

- $\evpi =$ £71,670 per 10 years

]

---

# Example &ndash; HIV screening decision model

## `R` code: Check convergence

.pull-left[
```{r eval=FALSE}
# Running mean to assess convergence
EVPI.run<-c(rep(0,150))
for (i in 1:150) {
 EVPI.run[i] <- 7.7217*mean(max.NBgain[1:(i*1000)])
}


# Plot running mean of EVPI
plot(seq(1000,150000,1000), EVPI.run, type="l",
     lty=1,xlab="Simulation", ylab="EVPI")
```
]

.pull-right[
`r include_fig("hiv-results2.png",width="120%")`
]

---

exclude: true
# EVPI using `BCEA`

- `BCEA` computes the EVPI automatically and returns it in an object called `evi`

    - If your `BCEA` object is called `m`, this is then accessible as `m$evi`

   
- This needs to be multiplied by population size (if not already accounted for in net-benefit) and also by the time horizon (appropriately discounted)


- **[See practical...](../../practical/11_intro_voi)**

---

# Pilot Studies for NIHR and NICE

- Claxton et al ([2004](https://njl-admin.nihr.ac.uk/document/download/2004777), [2005](https://www.york.ac.uk/che/pdf/claxtonnice.pdf)) conducted 2 pilot studies applying / integrating VOI to directly inform research priorities

   - NCCHTA (now NIHR NETSCC HTA) funds primary and secondary evaluative research
   
   - NICE issue guidance on the use of health technologies in the NHS
   
   - NICE also make research recommendations (but cannot commission research)

--

## Is further research required?

.red[**NO**]
- Physiotherapy for COPD or asthma in adults (EVPI = £0) 

.amber[**MAYBE**]
- Liquid based cytology (EVPI = £2.8m)
- AMD (EVPI = £25m)
- Children with asthma (EVPI = £15.7m)
- Recurrent UTI (EVPI = £4.6m)

.green[**YES**, a priority for:]
- Clopodogrel for stroke patients (EVPI = £865m): high prevalence
- NI for influenza (EVPI = £66.7m)
- Multiple sclerosis (EVPI = £86.2m)
- Glycoproteins (EVPI = £171m)

---

count: false
# Pilot Studies for NIHR and NICE

- Claxton et al ([2004](https://njl-admin.nihr.ac.uk/document/download/2004777), [2005](https://www.york.ac.uk/che/pdf/claxtonnice.pdf)) conducted 2 pilot studies applying / integrating VOI to directly inform research priorities

   - NCCHTA (now NIHR NETSCC HTA) funds primary and secondary evaluative research
   
   - NICE issue guidance on the use of health technologies in the NHS
   
   - NICE also make research recommendations (but cannot commission research)

## Which subgroups?

**Clopidogrel**

- Research of most value for stroke and MI groups, but high value for all


**AMD**

- EVPI is higher for those with lower starting visual acuity score 

**UTI**

- EVPI = £2.2m for non-infant girls with normal urinary tracts... but negligible for other risk groups (where low-dose anti-bacterial regimen is clearly cost-effective)

---

count: false
# Pilot Studies for NIHR and NICE

- Claxton et al ([2004](https://njl-admin.nihr.ac.uk/document/download/2004777), [2005](https://www.york.ac.uk/che/pdf/claxtonnice.pdf)) conducted 2 pilot studies applying / integrating VOI to directly inform research priorities

   - NCCHTA (now NIHR NETSCC HTA) funds primary and secondary evaluative research
   
   - NICE issue guidance on the use of health technologies in the NHS
   
   - NICE also make research recommendations (but cannot commission research)

## Which comparators?

**Multiple Sclerosis**

- EVPI higher for RCT of glatiramer acetate (£14m) and interferonb-1b (£13.6m) than interferonb-1a (£7m)

**UTIs**

- EVPI is highest for 2 prophylactic regimens, rather than intermittent treatment, suggesting head-to-head trial

**Asthma in children**

- EVPI highest for 2 therapies, suggesting head-to-head trial 

---

count: false
# Pilot Studies for NIHR and NICE

- Claxton et al ([2004](https://njl-admin.nihr.ac.uk/document/download/2004777), [2005](https://www.york.ac.uk/che/pdf/claxtonnice.pdf)) conducted 2 pilot studies applying / integrating VOI to directly inform research priorities

   - NCCHTA (now NIHR NETSCC HTA) funds primary and secondary evaluative research
   
   - NICE issue guidance on the use of health technologies in the NHS
   
   - NICE also make research recommendations (but cannot commission research)

## Comments

- Research priorities cannot be based on efficacy alone

   - Asthma/COPD in adults had highest uncertainty in effect, but EVPI = £0
   
   - Clopidogrel and glycoproteins had substantial evidence on some outcomes, but large EVPI
   
- This analysis requires us to investigate further (see `r ref_lecture("evppi")`)

.alignright[.small[`r icon::fontawesome("arrow-circle-right")` [Next lecture](../12_EVPPI/index.html)]]

