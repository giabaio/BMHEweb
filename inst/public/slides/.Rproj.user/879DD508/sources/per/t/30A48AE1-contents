---
title: "&#8291;7. Model error and structural uncertainty"
author: Gianluca Baio
institute: "[Department of Statistical Science](https://www.ucl.ac.uk/statistics/) | University College London"
params: 
   - conference: "Bayesian Methods in Health Economics"
   - location: "Lausanne"
date: 
output:
  xaringan::moon_reader:
    includes: 
       in_header: "../assets/latex_macros.html" 
       ## This line adds a logo based on the format selected in the file 'assets/THEME/include_logo.html'
       ## NB: the actual options (eg placement of the logo and actual logo file) can be changed there
       ## There's also a script to manipulate the colouring scheme for the UCL logo (from a basic black/white one)
       after_body: "../assets/beamer/insert-logo-ucl.html"
    seal: false
    yolo: no
    lib_dir: libs
    nature:
      beforeInit: ["https://platform.twitter.com/widgets.js"]
      highlightStyle: github 
      highlightLines: yes
      countIncrementalSlides: no
      ratio: '16:9'
      titleSlideClass:
      - center
      - middle
    self_contained: false 
    css:
    - "../assets/beamer.css"
---

```{r echo=F,message=FALSE,warning=FALSE,comment=NA}
# Sources the R file with all the relevant setup and commands
source("../assets/setup.R")

# Stuff from 'xaringanExtra' (https://pkg.garrickadenbuie.com/xaringanExtra)
# This allows the use of panels (from 'xaringanExtra')
xaringanExtra::use_panelset()
# This allows to copy code from the slides directly
xaringanExtra::use_clipboard()
# This freezes the frame for when there's a gif included
xaringanExtra::use_freezeframe()

# Defines the path to the file with the .bib entries (in case there are references)
bibfile=ReadBib("~/Dropbox/Perso/Office/CV/mypubs.bib",check = FALSE)

options(width=400)
```

```{r title-page, child="../assets/title-slide-gb.Rmd"}
```

# Summary

- Probabilistic sensitivity analysis to structural assumptions

   - Model average vs model comparison
   
   - Structural PSA using DIC
   
   - Example

`r vspace("4em")`

.content-box-beamer[
### **References** 

`r vspace("20px")`

`r bmhe(c("3.6","4.7.2"))`

`r bugs_book(8.6)`

]

---

# PSA to structural assumptions

## Problem

- All the methods discussed so far assume that, while there may be uncertainty in the
current knowledge, the model is “correct”

   - All variables that need to be considered have been considered
   
   - All distributional assumptions are reasonable (in fact, “correct”)
   
   - ...

`r vspace("20pt")`

--

> "All models are wrong, but some are useful" G. Box and N. Draper (1987).
[Empirical Model Building and Response Surfaces](https://www.amazon.co.uk/Empirical-Building-Response-Probability-Statistics/dp/0471810339), Wiley & Sons, NY, p. 424

`r vspace("20pt")`

--

- Possible (potential) solutions

   - Bayesian model averaging
   
   - Model comparison

---

# Bayesian model averaging

- “Proper” Bayesian way to deal with the issue

   - Identify a set of .red[*finite and exhaustive models* ] $\mathcal{M} = (\mathcal{M}_1,\ldots,\mathcal{M}_H)$
   
   - Each of the $H$ models is characterised by a set of parameters $\bm\theta$ and a suitable prior $p(\bm\theta\mid \mathcal{M}_h)$
   
   - In addition, define a prior $p(\mathcal{M}_h)$ that model $h$ is the "true" one
   
   - Update these as 
   
   $$\class{myblue}{p(\mathcal{M}_h \mid y) \propto p(\mathcal{M}_h) \int p(y \mid \bm\theta, \mathcal{M}_h) p(\bm\theta\mid \mathcal{M}_h)d\bm\theta}$$
   
   and use the posterior probabilities to compute a weighted average for any function of the parameters (eg utilities) over the space of models

`r vspace("20pt")`
--

- **NB**: requires that *all* possible models are completely specified and given a prior probability

---

# Model comparison

- Compare a (not necessarily exhaustive!) set of models in terms of their out-of-sample prediction

   - Quantifies how well the predictive distribution for a given model would fit a replicated dataset based on the observed data
   
   - **NB**: especially in health economic evaluations, the possible models considered as merely a (rough) approximation to the complex phenomenon under study &ndash; so no guarantee that any of those should be the “true” one!
   
`r vspace("20pt")`   

--

- Need to consider a measure of *goodness of fit* for each model

- **One** possibility is the Deviance Information Criterion (DIC)

--

## Structural PSA via DIC

- Consider $\mathcal{M} = (\mathcal{M}_1,\ldots,\mathcal{M}_H)$

   1. Compute the value $\DIC_h$ for each of them 
   2. Derive the respective weights (model posterior probabilities) by simply re-proportioning them, eg
   $$\class{myblue}{w_h = \frac{\exp(-0.5\Delta\DIC_h)}{\sum_{h=1}^H \exp(-0.5\Delta\DIC_h)}, \qquad \Delta\DIC_h = \mid \min_h(\DIC_h) - \DIC_h \mid}$$
   3. Use the weights $w_h$ to build an average model accounting for the (limited set) of plausible models


---

# Example &ndash; statins

.pull-left[
`r include_fig("data.png",width="55%")`
]

.pull-right[
- Based on published data on RCTs comparing statins to placebo

- Complex formulation: in particular, model the response for the controls as
\begin{align}
y_{sj}^{\text{ctr}} & \sim \dbin(\theta_s, n^{\text{ctr}}_{sj}) \\
\logit(\theta_s) & = \alpha_s
\end{align}
and then use 2 formulations for the prior on $\alpha_s$

1. .red[**Normal**] 
   - $\alpha_s \sim \dnorm(\mu_\alpha,\tau_\alpha)$
   - $\mu_\alpha \sim \dnorm(0, 0.00001)$
   - $\sigma_\alpha =\tau_\alpha^{-2} \sim \dunif(0,20)$
2. .blue[**Half-Cauchy**] (robust alternative)
   - $\alpha_s = \mu_\alpha + \xi \eta_s$
   - $\mu_\alpha \sim \dnorm(0, 0.00001)$
   - $\xi \sim \dnorm(0,\tau_\xi)$
   - $\eta_s \sim \dnorm(0,\tau_\eta)$
   - $\tau_\eta \sim \dgamma(0.5,0.5)$; $\tau_\xi = 12^{-2}$
]

---

count: false
# Example &ndash; statins

.pull-left[

Model $\mathcal{M}_1$

```{r eval=FALSE}
...
## Priors for the hyperparameters
## Exchangeable normal prior
for (s in 1:Nstatins) {
  alpha[s] ~ dnorm(mu.alpha, tau.alpha)
}
sigma.alpha ~ dunif(0,20)
tau.alpha <- pow(sigma.alpha,-2)
mu.alpha ~ dnorm(0,0.0001)
sigma.alpha <- abs(xi) / sqrt(tau.eta)
prior.scale <- 12
mu.alpha ~ dnorm(0,.0001)
...
```

]

.pull-right[

Model $\mathcal{M}_2$

```{r eval=FALSE}
...
## Priors for the hyperparameters
## Half-Cauchy prior
for (s in 1:Nstatins) {
  alpha[s] <- mu.alpha + xi*eta[s]
  eta[s] ~ dnorm(0,tau.eta)
}
xi ~ dnorm(0,tau.xi)
tau.xi <- pow(prior.scale,-2)
tau.eta ~ dgamma(.5,.5)
sigma.alpha <- abs(xi) / sqrt(tau.eta)
prior.scale <- 12
mu.alpha ~ dnorm(0,.0001)
...
```
]

---

count: false
# Example &ndash; statins

`print(m1)` $\class{red}{\rightarrow}$ .red[`R` object containing the MCMC simulations for] $\class{red}{\mathcal{M}_1}$
```{r echo=FALSE}
load("../../../content/practical/07_structural/statins_base.Rdata")
x=m1=statins_base
cat("Inference for Bugs model at \"model.txt\", fit using ", x$program, ",", x$n.chains, " chains, each with", format(x$n.iter,scientific=FALSE),"\niterations  (first ", x$n.burnin, " discarded), n.thin =", x$n.thin, "n.sims =", x$n.sims, "iterations saved\n")
print(round(x$summary[1:3,], digits=1))
cat("DIC info (using the rule, pD = var(deviance)/2)\npD = ",format(x$pD,digits=2,nsmall=1)," and DIC = ",format(x$DIC,digits=2,nsmall=1),"\nDIC is an estimate of expected predictive error (lower deviance is better)")
```

`r vspace("20pt")`
`print(m2)` $\class{blue}{\rightarrow}$ .blue[`R` object containing the MCMC simulations for] $\class{blue}{\mathcal{M}_2}$
```{r echo=FALSE}
load("../../../content/practical/07_structural/statins_HC.Rdata")
x2=m2=statins_HC
cat("Inference for Bugs model at \"model.txt\", fit using ", x2$program, ",", x2$n.chains, " chains, each with", format(x2$n.iter,scientific=FALSE),"\niterations  (first ", x2$n.burnin, " discarded), n.thin =", x2$n.thin, "n.sims =", x2$n.sims, "iterations saved\n")
print(round(x2$summary[1:3,], digits=1))
cat("DIC info (using the rule, pD = var(deviance)/2)\npD = ",format(x2$pD,digits=2,nsmall=1)," and DIC = ",format(x2$DIC,digits=2,nsmall=1),"\nDIC is an estimate of expected predictive error (lower deviance is better)")
```

---

count: false
# Example &ndash; statins

```{r echo=TRUE}
library(BCEA)
# Objects containing the MCMC simulations from the posteriors for the two models
m1.sims <- m1$sims.list;
m2.sims <- m2$sims.list

# Defines suitable variables of clinical benefits & costs
e1 <- m1.sims$effect;
e2 <- m2.sims$effect
c1 <- m1.sims$cost.tot;
c2 <- m2.sims$cost.tot

# Runs BCEA’s function to do PSA to structural assumptions
avg <- struct.psa(list(m1,m2),list(e1,e2),list(c1,c2),ref=2)
```

```{r echo=TRUE}
# Weights associated with each model (based on DIC)
avg$w
# Actual DIC computed for each model
avg$DIC
```
---

count: false
# Example &ndash; statins

```{r echo=FALSE}
interventions <- c("Atorvastatin","Fluvastatin","Lovastatin","Pravastatin",
                   "Rosuvastatin","Simvastatin")
m1 <- bcea(statins_base$sims.list$effect,statins_base$sims.list$cost.tot,ref=1,interventions=interventions)
m2 <- bcea(statins_HC$sims.list$effect,statins_HC$sims.list$cost.tot,ref=1,interventions=interventions)

# 3. Uses BCEA to do structural PSA
# Defines suitable lists containing:
models <- list(statins_base,statins_HC)             # the BUGS models
effects <- list(statins_base$sims.list$effect,      # the simulated effectiveness variables
                statins_HC$sims.list$effect)
costs <- list(statins_base$sims.list$cost.tot,      # the simulated cost variables
              statins_HC$sims.list$cost.tot)

# Finally uses BCEA to perform the structural PSA to consider the base and HC models
m3 <- struct.psa(models,effects,costs,ref=1,interventions=interventions)
```

.panelset[
.panel[
.panel-name[Model 1 (Normal prior)]
.pull-left[
```{r echo=FALSE}
plot(m1)
```
]
.pull-right[
- DIC = `r format(x$DIC,digits=3,nsmall=3)`
- $w_1$ = `r format(m3$w[1],digits=3,nsmall=3)`
]
]

.panel[
.panel-name[Model 2 (HC prior)]
.pull-left[
```{r echo=FALSE}
plot(m2)
```
]
.pull-right[
- DIC = `r format(x2$DIC,digits=3,nsmall=3)`
- $w_2$ = `r format(m3$w[2],digits=3,nsmall=3)`
]
]

.panel[
.panel-name[Model average]
```{r echo=FALSE,opts=list(width="50%",title="INSERT TEXT HERE")}
plot(m3$he)
```
]

]
---

count: false
# Example &ndash; statins

.pull-left[
Model $\mathcal{M}_2$
```{r echo=FALSE}
wtp=25000
he=m2
Table <- BCEA:::sim_table.bcea(he)$Table
EU_tab <- matrix(NA, he$n_comparators, 1)
EU_tab[, 1] <- unlist(Table[he$n_sim + 1, paste0("U", 1:he$n_comparators)])
colnames(EU_tab) <- "Expected utility"
rownames(EU_tab) <- he$interventions
comp_tab <- matrix(NA, he$n_comparisons, 3)
comp_tab[, 1] <- unlist(Table[he$n_sim + 1, paste0("IB", he$ref, "_", he$comp)])
if (he$n_comparisons == 1) {
    comp_tab[, 2] <- sum(Table[1:he$n_sim, paste0("IB", he$ref, "_", he$comp)] > 0)/he$n_sim
    comp_tab[, 3] <- he$ICER
}
if (he$n_comparisons > 1) {
    for (i in seq_len(he$n_comparisons)) {
        comp_tab[i, 2] <- sum(Table[1:he$n_sim, paste0("IB", he$ref, "_", he$comp[i])] > 0)/he$n_sim
        comp_tab[i, 3] <- he$ICER[i]
    }
}
colnames(comp_tab) <- c("EIB", "CEAC", "ICER")
rownames(comp_tab) <- paste0(he$interventions[he$ref], " vs ", he$interventions[he$comp])
evpi_tab <- matrix(NA, 1, 1)
evpi_tab[, 1] <- Table[he$n_sim + 1, "VI"]
rownames(evpi_tab) <- "EVPI"
colnames(evpi_tab) <- ""
cat(paste0("Analysis for willingness to pay parameter k = ", wtp, "\n"))
cat("\n")
print(EU_tab, quote = FALSE, digits = 5, justify = "center")
cat("\n")
print(comp_tab, quote = FALSE, digits = 5, justify = "center")
cat("\n")
cat(paste0("Optimal intervention (max expected utility) \nfor k = ", wtp, ": ", he$interventions[m1$best][m1$k == wtp], "\n"))
print(evpi_tab, quote = FALSE, digits = 5, justify = "center")
```
]
.pull-right[
Model average
```{r echo=FALSE}
wtp=25000
he=m3$he
Table <- BCEA:::sim_table.bcea(he)$Table
EU_tab <- matrix(NA, he$n_comparators, 1)
EU_tab[, 1] <- unlist(Table[he$n_sim + 1, paste0("U", 1:he$n_comparators)])
colnames(EU_tab) <- "Expected utility"
rownames(EU_tab) <- he$interventions
comp_tab <- matrix(NA, he$n_comparisons, 3)
comp_tab[, 1] <- unlist(Table[he$n_sim + 1, paste0("IB", he$ref, "_", he$comp)])
if (he$n_comparisons == 1) {
    comp_tab[, 2] <- sum(Table[1:he$n_sim, paste0("IB", he$ref, "_", he$comp)] > 0)/he$n_sim
    comp_tab[, 3] <- he$ICER
}
if (he$n_comparisons > 1) {
    for (i in seq_len(he$n_comparisons)) {
        comp_tab[i, 2] <- sum(Table[1:he$n_sim, paste0("IB", he$ref, "_", he$comp[i])] > 0)/he$n_sim
        comp_tab[i, 3] <- he$ICER[i]
    }
}
colnames(comp_tab) <- c("EIB", "CEAC", "ICER")
rownames(comp_tab) <- paste0(he$interventions[he$ref], " vs ", he$interventions[he$comp])
evpi_tab <- matrix(NA, 1, 1)
evpi_tab[, 1] <- Table[he$n_sim + 1, "VI"]
rownames(evpi_tab) <- "EVPI"
colnames(evpi_tab) <- ""
cat(paste0("Analysis for willingness to pay parameter k = ", wtp, "\n"))
cat("\n")
print(EU_tab, quote = FALSE, digits = 5, justify = "center")
cat("\n")
print(comp_tab, quote = FALSE, digits = 5, justify = "center")
cat("\n")
cat(paste0("Optimal intervention (max expected utility) \nfor k = ", wtp, ": ", he$interventions[m1$best][m1$k == wtp], "\n"))
print(evpi_tab, quote = FALSE, digits = 5, justify = "center")
```
]

`r vspace("1em")`

.alignright[.small[`r icon::fontawesome("arrow-circle-right")` [Next lecture](../08_Survival/index.html)]]
