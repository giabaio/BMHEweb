<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>‚Å£1. Introduction to Bayesian reasoning, computation and BUGS</title>
    <meta charset="utf-8" />
    <meta name="author" content="Gianluca Baio" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <script src="libs/freezeframe/freezeframe.min.js"></script>
    <script src="libs/xaringanExtra-freezeframe/freezeframe-init.js"></script>
    <script id="xaringanExtra-freezeframe-options" type="application/json">{"selector":"img[src$=\"gif\"]","trigger":"click","overlay":false,"responsive":true,"warnings":true}</script>
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <!-- (Re)Defines a bunch of LaTeX commands that can then be used directly in the .Rmd file as '\command{...}' -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      TeX: {
        /* This enables color macros */
        extensions: ["color.js"],
        Macros: {
          /* Probability & mathematical symbols */
          Pr: "{\\style{font-family:inherit; font-size: 110%;}{\\text{Pr}}}",
          exp: "{\\style{font-family:inherit; font-size: 105%;}{\\text{exp}}}",
          log: "{\\style{font-family:inherit; font-size: 105%;}{\\text{log}}}",
          ln: "{\\style{font-family:inherit; font-size: 105%;}{\\text{ln}}}",
          logit: "{\\style{font-family:inherit; font-size: 100%;}{\\text{logit}}}",
          HR: "{\\style{font-family:inherit; font-size: 105%;}{\\text{HR}}}",
          OR: "{\\style{font-family:inherit; font-size: 105%;}{\\text{OR}}}",
          E: "{\\style{font-family:inherit; font-size: 105%;}{\\text{E}}}",
          Var: "{\\style{font-family:inherit; font-size: 105%;}{\\text{Var}}}",
          Cov: "{\\style{font-family:inherit; font-size: 105%;}{\\text{Cov}}}",
          Corr: "{\\style{font-family:inherit; font-size: 105%;}{\\text{Corr}}}",
          DIC: "{\\style{font-family:inherit; font-size: 105%;}{\\text{DIC}}}",
          se: "{\\style{font-family:inherit; font-size: 100%;}{\\text{se}}}",
          sd: "{\\style{font-family:inherit; font-size: 100%;}{\\text{sd}}}",
          kld: "{\\style{font-family:inherit; font-size: 100%;}{\\text{KLD}}}",
          /* Distributions */
          dnorm: "{\\style{font-family:inherit;}{\\text{Normal}}}",
          dt: "{\\style{font-family:inherit;}{\\text{t}}}",
          ddirch: "{\\style{font-family:inherit;}{\\text{Dirichlet}}}",
          dmulti: "{\\style{font-family:inherit;}{\\text{Multinomial}}}",
          dbeta: "{\\style{font-family:inherit;}{\\text{Beta}}}",
          dgamma: "{\\style{font-family:inherit;}{\\text{Gamma}}}",
          dbern: "{\\style{font-family:inherit;}{\\text{Bernoulli}}}",
          dbin: "{\\style{font-family:inherit;}{\\text{Binomial}}}",
          dpois: "{\\style{font-family:inherit;}{\\text{Poisson}}}",
          dweib: "{\\style{font-family:inherit;}{\\text{Weibull}}}",
          dexp: "{\\style{font-family:inherit;}{\\text{Exponential}}}",
          dlnorm: "{\\style{font-family:inherit;}{\\text{logNormal}}}",
          dunif: "{\\style{font-family:inherit;}{\\text{Uniform}}}",
          /* LaTeX formatting */
          bm: ["{\\boldsymbol #1}",1],
          /* These create macros to typeset numbers in maths with the basic font */
          0: "{\\style{font-family:inherit; font-size: 105%;}{\\text{0}}}",
          1: "{\\style{font-family:inherit; font-size: 105%;}{\\text{1}}}",
          2: "{\\style{font-family:inherit; font-size: 105%;}{\\text{2}}}",
          3: "{\\style{font-family:inherit; font-size: 105%;}{\\text{3}}}",
          4: "{\\style{font-family:inherit; font-size: 105%;}{\\text{4}}}",
          5: "{\\style{font-family:inherit; font-size: 105%;}{\\text{5}}}",
          6: "{\\style{font-family:inherit; font-size: 105%;}{\\text{6}}}",
          7: "{\\style{font-family:inherit; font-size: 105%;}{\\text{7}}}",
          8: "{\\style{font-family:inherit; font-size: 105%;}{\\text{8}}}",
          9: "{\\style{font-family:inherit; font-size: 105%;}{\\text{9}}}",
          /* Health economics quantities */
          icer: "{\\style{font-family:inherit; font-size: 100%;}{\\text{ICER}}}",
          nb: "{\\style{font-family:inherit; font-size: 100%;}{\\text{NB}}}",
          ib: "{\\style{font-family:inherit; font-size: 100%;}{\\text{IB}}}",
          eib: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EIB}}}",
          ol: "{\\style{font-family:inherit; font-size: 100%;}{\\text{OL}}}",
          ceac: "{\\style{font-family:inherit; font-size: 100%;}{\\text{CEAC}}}",
          evpi: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EVPI}}}",
          evppi: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EVPPI}}}",
          evsi: "{\\style{font-family:inherit; font-size: 100%;}{\\text{EVSI}}}"
        }
      }
    });
    </script>
    <link rel="stylesheet" href="../assets/beamer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">





class: title-slide

# &amp;#8291;1. Introduction to Bayesian reasoning, computation and BUGS

## Gianluca Baio

### [Department of Statistical Science](https://www.ucl.ac.uk/statistics/) | University College London    

.title-small[
&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:#00acee;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"&gt;&lt;/path&gt;&lt;/svg&gt;  [g.baio@ucl.ac.uk](mailto:g.baio@ucl.ac.uk)
&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:#EA7600;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M503.52,241.48c-.12-1.56-.24-3.12-.24-4.68v-.12l-.36-4.68v-.12a245.86,245.86,0,0,0-7.32-41.15c0-.12,0-.12-.12-.24l-1.08-4c-.12-.24-.12-.48-.24-.6-.36-1.2-.72-2.52-1.08-3.72-.12-.24-.12-.6-.24-.84-.36-1.2-.72-2.4-1.08-3.48-.12-.36-.24-.6-.36-1-.36-1.2-.72-2.28-1.2-3.48l-.36-1.08c-.36-1.08-.84-2.28-1.2-3.36a8.27,8.27,0,0,0-.36-1c-.48-1.08-.84-2.28-1.32-3.36-.12-.24-.24-.6-.36-.84-.48-1.2-1-2.28-1.44-3.48,0-.12-.12-.24-.12-.36-1.56-3.84-3.24-7.68-5-11.4l-.36-.72c-.48-1-.84-1.8-1.32-2.64-.24-.48-.48-1.08-.72-1.56-.36-.84-.84-1.56-1.2-2.4-.36-.6-.6-1.2-1-1.8s-.84-1.44-1.2-2.28c-.36-.6-.72-1.32-1.08-1.92s-.84-1.44-1.2-2.16a18.07,18.07,0,0,0-1.2-2c-.36-.72-.84-1.32-1.2-2s-.84-1.32-1.2-2-.84-1.32-1.2-1.92-.84-1.44-1.32-2.16a15.63,15.63,0,0,0-1.2-1.8L463.2,119a15.63,15.63,0,0,0-1.2-1.8c-.48-.72-1.08-1.56-1.56-2.28-.36-.48-.72-1.08-1.08-1.56l-1.8-2.52c-.36-.48-.6-.84-1-1.32-1-1.32-1.8-2.52-2.76-3.72a248.76,248.76,0,0,0-23.51-26.64A186.82,186.82,0,0,0,412,62.46c-4-3.48-8.16-6.72-12.48-9.84a162.49,162.49,0,0,0-24.6-15.12c-2.4-1.32-4.8-2.52-7.2-3.72a254,254,0,0,0-55.43-19.56c-1.92-.36-3.84-.84-5.64-1.2h-.12c-1-.12-1.8-.36-2.76-.48a236.35,236.35,0,0,0-38-4H255.14a234.62,234.62,0,0,0-45.48,5c-33.59,7.08-63.23,21.24-82.91,39-1.08,1-1.92,1.68-2.4,2.16l-.48.48H124l-.12.12.12-.12a.12.12,0,0,0,.12-.12l-.12.12a.42.42,0,0,1,.24-.12c14.64-8.76,34.92-16,49.44-19.56l5.88-1.44c.36-.12.84-.12,1.2-.24,1.68-.36,3.36-.72,5.16-1.08.24,0,.6-.12.84-.12C250.94,20.94,319.34,40.14,367,85.61a171.49,171.49,0,0,1,26.88,32.76c30.36,49.2,27.48,111.11,3.84,147.59-34.44,53-111.35,71.27-159,24.84a84.19,84.19,0,0,1-25.56-59,74.05,74.05,0,0,1,6.24-31c1.68-3.84,13.08-25.67,18.24-24.59-13.08-2.76-37.55,2.64-54.71,28.19-15.36,22.92-14.52,58.2-5,83.28a132.85,132.85,0,0,1-12.12-39.24c-12.24-82.55,43.31-153,94.31-170.51-27.48-24-96.47-22.31-147.71,15.36-29.88,22-51.23,53.16-62.51,90.36,1.68-20.88,9.6-52.08,25.8-83.88-17.16,8.88-39,37-49.8,62.88-15.6,37.43-21,82.19-16.08,124.79.36,3.24.72,6.36,1.08,9.6,19.92,117.11,122,206.38,244.78,206.38C392.77,503.42,504,392.19,504,255,503.88,250.48,503.76,245.92,503.52,241.48Z"&gt;&lt;/path&gt;&lt;/svg&gt;  [https://gianluca.statistica.it/](https://gianluca.statistica.it/)
&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:#EA7600;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M503.52,241.48c-.12-1.56-.24-3.12-.24-4.68v-.12l-.36-4.68v-.12a245.86,245.86,0,0,0-7.32-41.15c0-.12,0-.12-.12-.24l-1.08-4c-.12-.24-.12-.48-.24-.6-.36-1.2-.72-2.52-1.08-3.72-.12-.24-.12-.6-.24-.84-.36-1.2-.72-2.4-1.08-3.48-.12-.36-.24-.6-.36-1-.36-1.2-.72-2.28-1.2-3.48l-.36-1.08c-.36-1.08-.84-2.28-1.2-3.36a8.27,8.27,0,0,0-.36-1c-.48-1.08-.84-2.28-1.32-3.36-.12-.24-.24-.6-.36-.84-.48-1.2-1-2.28-1.44-3.48,0-.12-.12-.24-.12-.36-1.56-3.84-3.24-7.68-5-11.4l-.36-.72c-.48-1-.84-1.8-1.32-2.64-.24-.48-.48-1.08-.72-1.56-.36-.84-.84-1.56-1.2-2.4-.36-.6-.6-1.2-1-1.8s-.84-1.44-1.2-2.28c-.36-.6-.72-1.32-1.08-1.92s-.84-1.44-1.2-2.16a18.07,18.07,0,0,0-1.2-2c-.36-.72-.84-1.32-1.2-2s-.84-1.32-1.2-2-.84-1.32-1.2-1.92-.84-1.44-1.32-2.16a15.63,15.63,0,0,0-1.2-1.8L463.2,119a15.63,15.63,0,0,0-1.2-1.8c-.48-.72-1.08-1.56-1.56-2.28-.36-.48-.72-1.08-1.08-1.56l-1.8-2.52c-.36-.48-.6-.84-1-1.32-1-1.32-1.8-2.52-2.76-3.72a248.76,248.76,0,0,0-23.51-26.64A186.82,186.82,0,0,0,412,62.46c-4-3.48-8.16-6.72-12.48-9.84a162.49,162.49,0,0,0-24.6-15.12c-2.4-1.32-4.8-2.52-7.2-3.72a254,254,0,0,0-55.43-19.56c-1.92-.36-3.84-.84-5.64-1.2h-.12c-1-.12-1.8-.36-2.76-.48a236.35,236.35,0,0,0-38-4H255.14a234.62,234.62,0,0,0-45.48,5c-33.59,7.08-63.23,21.24-82.91,39-1.08,1-1.92,1.68-2.4,2.16l-.48.48H124l-.12.12.12-.12a.12.12,0,0,0,.12-.12l-.12.12a.42.42,0,0,1,.24-.12c14.64-8.76,34.92-16,49.44-19.56l5.88-1.44c.36-.12.84-.12,1.2-.24,1.68-.36,3.36-.72,5.16-1.08.24,0,.6-.12.84-.12C250.94,20.94,319.34,40.14,367,85.61a171.49,171.49,0,0,1,26.88,32.76c30.36,49.2,27.48,111.11,3.84,147.59-34.44,53-111.35,71.27-159,24.84a84.19,84.19,0,0,1-25.56-59,74.05,74.05,0,0,1,6.24-31c1.68-3.84,13.08-25.67,18.24-24.59-13.08-2.76-37.55,2.64-54.71,28.19-15.36,22.92-14.52,58.2-5,83.28a132.85,132.85,0,0,1-12.12-39.24c-12.24-82.55,43.31-153,94.31-170.51-27.48-24-96.47-22.31-147.71,15.36-29.88,22-51.23,53.16-62.51,90.36,1.68-20.88,9.6-52.08,25.8-83.88-17.16,8.88-39,37-49.8,62.88-15.6,37.43-21,82.19-16.08,124.79.36,3.24.72,6.36,1.08,9.6,19.92,117.11,122,206.38,244.78,206.38C392.77,503.42,504,392.19,504,255,503.88,250.48,503.76,245.92,503.52,241.48Z"&gt;&lt;/path&gt;&lt;/svg&gt;  [https://egon.stats.ucl.ac.uk/research/statistics-health-economics/](https://egon.stats.ucl.ac.uk/research/statistics-health-economics/)
&lt;svg viewBox="0 0 496 512" style="position:relative;display:inline-block;top:.1em;fill:black;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"&gt;&lt;/path&gt;&lt;/svg&gt;  [https://github.com/giabaio](https://github.com/giabaio)
&lt;svg viewBox="0 0 496 512" style="position:relative;display:inline-block;top:.1em;fill:black;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"&gt;&lt;/path&gt;&lt;/svg&gt;  [https://github.com/StatisticsHealthEconomics](https://github.com/StatisticsHealthEconomics)
&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:#00acee;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"&gt;&lt;/path&gt;&lt;/svg&gt;  [@gianlubaio](https://twitter.com/gianlubaio)     
]

### Bayesian Methods in Health Economics, Lausanne

---

layout: true

.my-footer[ 
.alignleft[
&amp;nbsp; &amp;copy; Gianluca Baio (UCL) &amp;nbsp;&lt;a href="https://twitter.com/giabaio"; title="Follow me on Twitter"&gt;&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:#bcc0c4;height:0.8em;bottom:1em;" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="https://github.com/giabaio"; title="Check out my repos"&gt;&lt;svg viewBox="0 0 496 512" style="position:relative;display:inline-block;top:.1em;fill:#bcc0c4;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="mailto:g.baio@ucl.ac.uk"; title="Email me"&gt;&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:#bcc0c4;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="https://gianluca.statistica.it"; title="Visit my website"&gt;&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:#bcc0c4;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;path d="M503.52,241.48c-.12-1.56-.24-3.12-.24-4.68v-.12l-.36-4.68v-.12a245.86,245.86,0,0,0-7.32-41.15c0-.12,0-.12-.12-.24l-1.08-4c-.12-.24-.12-.48-.24-.6-.36-1.2-.72-2.52-1.08-3.72-.12-.24-.12-.6-.24-.84-.36-1.2-.72-2.4-1.08-3.48-.12-.36-.24-.6-.36-1-.36-1.2-.72-2.28-1.2-3.48l-.36-1.08c-.36-1.08-.84-2.28-1.2-3.36a8.27,8.27,0,0,0-.36-1c-.48-1.08-.84-2.28-1.32-3.36-.12-.24-.24-.6-.36-.84-.48-1.2-1-2.28-1.44-3.48,0-.12-.12-.24-.12-.36-1.56-3.84-3.24-7.68-5-11.4l-.36-.72c-.48-1-.84-1.8-1.32-2.64-.24-.48-.48-1.08-.72-1.56-.36-.84-.84-1.56-1.2-2.4-.36-.6-.6-1.2-1-1.8s-.84-1.44-1.2-2.28c-.36-.6-.72-1.32-1.08-1.92s-.84-1.44-1.2-2.16a18.07,18.07,0,0,0-1.2-2c-.36-.72-.84-1.32-1.2-2s-.84-1.32-1.2-2-.84-1.32-1.2-1.92-.84-1.44-1.32-2.16a15.63,15.63,0,0,0-1.2-1.8L463.2,119a15.63,15.63,0,0,0-1.2-1.8c-.48-.72-1.08-1.56-1.56-2.28-.36-.48-.72-1.08-1.08-1.56l-1.8-2.52c-.36-.48-.6-.84-1-1.32-1-1.32-1.8-2.52-2.76-3.72a248.76,248.76,0,0,0-23.51-26.64A186.82,186.82,0,0,0,412,62.46c-4-3.48-8.16-6.72-12.48-9.84a162.49,162.49,0,0,0-24.6-15.12c-2.4-1.32-4.8-2.52-7.2-3.72a254,254,0,0,0-55.43-19.56c-1.92-.36-3.84-.84-5.64-1.2h-.12c-1-.12-1.8-.36-2.76-.48a236.35,236.35,0,0,0-38-4H255.14a234.62,234.62,0,0,0-45.48,5c-33.59,7.08-63.23,21.24-82.91,39-1.08,1-1.92,1.68-2.4,2.16l-.48.48H124l-.12.12.12-.12a.12.12,0,0,0,.12-.12l-.12.12a.42.42,0,0,1,.24-.12c14.64-8.76,34.92-16,49.44-19.56l5.88-1.44c.36-.12.84-.12,1.2-.24,1.68-.36,3.36-.72,5.16-1.08.24,0,.6-.12.84-.12C250.94,20.94,319.34,40.14,367,85.61a171.49,171.49,0,0,1,26.88,32.76c30.36,49.2,27.48,111.11,3.84,147.59-34.44,53-111.35,71.27-159,24.84a84.19,84.19,0,0,1-25.56-59,74.05,74.05,0,0,1,6.24-31c1.68-3.84,13.08-25.67,18.24-24.59-13.08-2.76-37.55,2.64-54.71,28.19-15.36,22.92-14.52,58.2-5,83.28a132.85,132.85,0,0,1-12.12-39.24c-12.24-82.55,43.31-153,94.31-170.51-27.48-24-96.47-22.31-147.71,15.36-29.88,22-51.23,53.16-62.51,90.36,1.68-20.88,9.6-52.08,25.8-83.88-17.16,8.88-39,37-49.8,62.88-15.6,37.43-21,82.19-16.08,124.79.36,3.24.72,6.36,1.08,9.6,19.92,117.11,122,206.38,244.78,206.38C392.77,503.42,504,392.19,504,255,503.88,250.48,503.76,245.92,503.52,241.48Z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp;
]
.aligncenter[
.mydropdown[ 
.mydropbtn[
&lt;svg viewBox="0 0 512 512" style="position:relative;display:inline-block;top:.1em;fill:white;height:0.8em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zM273 369.9l135.5-135.5c9.4-9.4 9.4-24.6 0-33.9l-17-17c-9.4-9.4-24.6-9.4-33.9 0L256 285.1 154.4 183.5c-9.4-9.4-24.6-9.4-33.9 0l-17 17c-9.4 9.4-9.4 24.6 0 33.9L239 369.9c9.4 9.4 24.6 9.4 34 0z"&gt;&lt;/path&gt;&lt;/svg&gt; 
]
.mydropdown-content[
[1. Introduction](../01_Intro/index.html)
[2. MCMC](../02_MCMC/index.html)
[3. Intro HTA](../03_Intro_HE/index.html)
[4. ILD](../04_ILD/index.html)
[5. ALD](../05_ALD/index.html)
[6. NMA](../06_NMA/index.html)
[7. Model uncertainty](../07_Model_uncertainty/index.html)
[8. Survival](../06_Survival/index.html)
[9. Markov models](../09_MM/index.html)
[10. Missing data](../10_Missing/index.html)
[11. VoI](../11_VoI/index.html)
[12. EVPPI](../12_EVPPI/index.html)
[13. Intro EVSI](../13_EVSI/index.html)
[14. Data EVSI](../14_Data_EVSI/index.html)
[15. EVSI MC](../15_EVSI_MC/index.html)
[16. EVSI Regression](../16_EVSI_regression/index.html)
]
]
&amp;#8291;1. Introduction to Bayesian reasoning, computation and BUGS 
]
.alignright[
&amp;nbsp;&lt;a target="_self" href="../../index.html"; title="Back to the summer school website"&gt;&lt;svg viewBox="0 0 576 512" style="position:relative;display:inline-block;top:.1em;fill:#bcc0c4;height:1em;bottom:1em;" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;path d="M280.37 148.26L96 300.11V464a16 16 0 0 0 16 16l112.06-.29a16 16 0 0 0 15.92-16V368a16 16 0 0 1 16-16h64a16 16 0 0 1 16 16v95.64a16 16 0 0 0 16 16.05L464 480a16 16 0 0 0 16-16V300L295.67 148.26a12.19 12.19 0 0 0-15.3 0zM571.6 251.47L488 182.56V44.05a12 12 0 0 0-12-12h-56a12 12 0 0 0-12 12v72.61L318.47 43a48 48 0 0 0-61 0L4.34 251.47a12 12 0 0 0-1.6 16.9l25.5 31A12 12 0 0 0 45.15 301l235.22-193.74a12.19 12.19 0 0 1 15.3 0L530.9 301a12 12 0 0 0 16.9-1.6l25.5-31a12 12 0 0 0-1.7-16.93z"&gt;&lt;/path&gt;
&lt;/svg&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp; BMHE 
]
] 

---

# Objective of this course

.pull-left[
&lt;center&gt;&lt;img src=./img/sheldon.png width='430px' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=./img/sheldon_penny.png width='430px' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;
]
.pull-right[
&lt;span style="display:block; margin-top: 1em ;"&gt;&lt;/span&gt;
- Introduction to .red[Bayesian analysis]
   - MCMC methods
   - Using `R` and `BUGS`

- Apply Bayesian analysis to .red[health economic evaluations]
   - Cost-effectiveness analysis
   - Probabilistic sensitiity analysis
   - Advanced modelling
   
&lt;span style="display:block; margin-top: 3em ;"&gt;&lt;/span&gt;

- Emphasis on **practical examples**
   - `BUGS` analysis
   - `R`/`BUGS` and `BCEA`
   - Problem-specific vs standardised analysis
]

---

# Relevant resources

The course [website](../index.html) contains all the relevant information

- [Reading list](../../publication/index.html)

- [Course description &amp; assessment](../../index.html#description)

- [Full timetable](../../index.html#timetable)

- [Full syllabus](../../syllabus)

- [Useful tips](../../tips) of the computer specification (for the practicals)

All the lecture slides are also available from the main page (see top menu under "Slides")

The material for the computer practicals is also available from the main page (see top menu under "Practicals")

.content-box-beamer[
### 
&lt;p style="margin-left: 0em;"&gt;&lt;i class="fas fa-info-circle" style="color: #5b7fd9;"&gt;&lt;/i&gt; The relevant slides and practical material will be made available &lt;b&gt;before&lt;/b&gt; the scheduled lecture. 

&lt;p style="margin-left: 1.4xem;"&gt;Annotated solutions to the practicals will also be made available &lt;b&gt;after&lt;/b&gt; the sessions.&lt;/p&gt;
]

--

&lt;span style="display:block; margin-top: 30px ;"&gt;&lt;/span&gt;

- Some &lt;svg viewBox="0 0 581 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  [ comment ]  &lt;path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"&gt;&lt;/path&gt;&lt;/svg&gt; resources: 
   - [This](https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf) is a very comprehensive introduction.
   - [This](https://r4ds.had.co.nz/introduction.html) is also a very good introduction, particularly around many of the more modern features of R (e.g. the [`tidyverse`](https://www.tidyverse.org/) package/approach).

- NICE Decision Support Unit website: [http://nicedsu.org.uk/](http://nicedsu.org.uk/)

- Moodle page (UCL-registered): [https://moodle.ucl.ac.uk/course/view.php?id=8596](https://moodle.ucl.ac.uk/course/view.php?id=8596)

---

# Reds vs Blues

&lt;center&gt;&lt;img src=./img/books.png width='920px' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;

---

# Disclaimer...

&lt;center&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p lang="en" dir="ltr"&gt;Best opening sentence &lt;a href="https://twitter.com/hashtag/ISPOREurope?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#ISPOREurope&lt;/a&gt; from Gianluca Baio: ‚Äústatisticians should rule the world and Bayesian statisticians should rule all statisticians‚Äù &lt;a href="https://t.co/GN2w7liAcR"&gt;https://t.co/GN2w7liAcR&lt;/a&gt;&lt;/p&gt;&amp;mdash; Manuela Joore (@ManuelaJoore) &lt;a href="https://twitter.com/ManuelaJoore/status/1191397718930939904?ref_src=twsrc%5Etfw"&gt;November 4, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt; 
&lt;/center&gt;

&lt;span style="display:block; margin-top: 2rem ;"&gt;&lt;/span&gt;
...Just so you know what you're about to get into... üòâ

---

# Summary 

- Deductive inference
   - "Standard" statistical methods

- Inductive inference
   - Bayesian reasoning
   - Basic ideas

- The Bayesian view making *probability statements about parameters*
   - *Quantities* that control reality (patient's risk of disease, treatment effects `\(\ldots\)`)
   - Don't / can't know them for sure
   - Can express this *uncertainty* using tools of *probability*

- Examples of probability distributions

- Monte Carlo simulation for prediction under uncertainty

- Implementation in `BUGS`

&lt;span style="display:block; margin-top: 2rem ;"&gt;&lt;/span&gt;

.content-box-beamer[
### References 
&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

&lt;svg viewBox="0 0 448 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;
  [ comment ]
  &lt;path d="M448 360V24c0-13.3-10.7-24-24-24H96C43 0 0 43 0 96v320c0 53 43 96 96 96h328c13.3 0 24-10.7 24-24v-16c0-7.5-3.5-14.3-8.9-18.7-4.2-15.4-4.2-59.3 0-74.7 5.4-4.3 8.9-11.1 8.9-18.6zM128 134c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm0 64c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm253.4 250H96c-17.7 0-32-14.3-32-32 0-17.6 14.4-32 32-32h285.4c-1.9 17.1-1.9 46.9 0 64z"&gt;&lt;/path&gt;
&lt;/svg&gt; &lt;i&gt;The BUGS Book&lt;/i&gt;, chapters 1, 2, 5 .button[&lt;img src="../img/routledge.png" width="10%"&gt; [Book website](https://www.routledge.com/The-BUGS-Book-A-Practical-Introduction-to-Bayesian-Analysis/Lunn-Jackson-Best-Thomas-Spiegelhalter/p/book/9781584888499)]

&lt;svg viewBox="0 0 448 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;
  [ comment ]
  &lt;path d="M448 360V24c0-13.3-10.7-24-24-24H96C43 0 0 43 0 96v320c0 53 43 96 96 96h328c13.3 0 24-10.7 24-24v-16c0-7.5-3.5-14.3-8.9-18.7-4.2-15.4-4.2-59.3 0-74.7 5.4-4.3 8.9-11.1 8.9-18.6zM128 134c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm0 64c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm253.4 250H96c-17.7 0-32-14.3-32-32 0-17.6 14.4-32 32-32h285.4c-1.9 17.1-1.9 46.9 0 64z"&gt;&lt;/path&gt;
&lt;/svg&gt; &lt;i&gt;Bayesian Methods in Health Economics&lt;/i&gt;, chapters 2, 4 .button[&lt;img src="../img/routledge.png" width="7%"&gt; [Book website (CRC)](https://www-taylorfrancis-com.libproxy.ucl.ac.uk/books/9780429111396)] .button[&lt;i class="fab fa-firefox"&gt;&lt;/i&gt; [Book website](https://gianluca.statistica.it/bmhe)] .button[&lt;i class="fab fa-github"&gt;&lt;/i&gt; [Code](https://github.com/giabaio/BCEA)]

&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  [ comment ]  &lt;path d="M503.52,241.48c-.12-1.56-.24-3.12-.24-4.68v-.12l-.36-4.68v-.12a245.86,245.86,0,0,0-7.32-41.15c0-.12,0-.12-.12-.24l-1.08-4c-.12-.24-.12-.48-.24-.6-.36-1.2-.72-2.52-1.08-3.72-.12-.24-.12-.6-.24-.84-.36-1.2-.72-2.4-1.08-3.48-.12-.36-.24-.6-.36-1-.36-1.2-.72-2.28-1.2-3.48l-.36-1.08c-.36-1.08-.84-2.28-1.2-3.36a8.27,8.27,0,0,0-.36-1c-.48-1.08-.84-2.28-1.32-3.36-.12-.24-.24-.6-.36-.84-.48-1.2-1-2.28-1.44-3.48,0-.12-.12-.24-.12-.36-1.56-3.84-3.24-7.68-5-11.4l-.36-.72c-.48-1-.84-1.8-1.32-2.64-.24-.48-.48-1.08-.72-1.56-.36-.84-.84-1.56-1.2-2.4-.36-.6-.6-1.2-1-1.8s-.84-1.44-1.2-2.28c-.36-.6-.72-1.32-1.08-1.92s-.84-1.44-1.2-2.16a18.07,18.07,0,0,0-1.2-2c-.36-.72-.84-1.32-1.2-2s-.84-1.32-1.2-2-.84-1.32-1.2-1.92-.84-1.44-1.32-2.16a15.63,15.63,0,0,0-1.2-1.8L463.2,119a15.63,15.63,0,0,0-1.2-1.8c-.48-.72-1.08-1.56-1.56-2.28-.36-.48-.72-1.08-1.08-1.56l-1.8-2.52c-.36-.48-.6-.84-1-1.32-1-1.32-1.8-2.52-2.76-3.72a248.76,248.76,0,0,0-23.51-26.64A186.82,186.82,0,0,0,412,62.46c-4-3.48-8.16-6.72-12.48-9.84a162.49,162.49,0,0,0-24.6-15.12c-2.4-1.32-4.8-2.52-7.2-3.72a254,254,0,0,0-55.43-19.56c-1.92-.36-3.84-.84-5.64-1.2h-.12c-1-.12-1.8-.36-2.76-.48a236.35,236.35,0,0,0-38-4H255.14a234.62,234.62,0,0,0-45.48,5c-33.59,7.08-63.23,21.24-82.91,39-1.08,1-1.92,1.68-2.4,2.16l-.48.48H124l-.12.12.12-.12a.12.12,0,0,0,.12-.12l-.12.12a.42.42,0,0,1,.24-.12c14.64-8.76,34.92-16,49.44-19.56l5.88-1.44c.36-.12.84-.12,1.2-.24,1.68-.36,3.36-.72,5.16-1.08.24,0,.6-.12.84-.12C250.94,20.94,319.34,40.14,367,85.61a171.49,171.49,0,0,1,26.88,32.76c30.36,49.2,27.48,111.11,3.84,147.59-34.44,53-111.35,71.27-159,24.84a84.19,84.19,0,0,1-25.56-59,74.05,74.05,0,0,1,6.24-31c1.68-3.84,13.08-25.67,18.24-24.59-13.08-2.76-37.55,2.64-54.71,28.19-15.36,22.92-14.52,58.2-5,83.28a132.85,132.85,0,0,1-12.12-39.24c-12.24-82.55,43.31-153,94.31-170.51-27.48-24-96.47-22.31-147.71,15.36-29.88,22-51.23,53.16-62.51,90.36,1.68-20.88,9.6-52.08,25.8-83.88-17.16,8.88-39,37-49.8,62.88-15.6,37.43-21,82.19-16.08,124.79.36,3.24.72,6.36,1.08,9.6,19.92,117.11,122,206.38,244.78,206.38C392.77,503.42,504,392.19,504,255,503.88,250.48,503.76,245.92,503.52,241.48Z"&gt;&lt;/path&gt;&lt;/svg&gt; [https://gianluca.statistica.it/teaching/intro-stats/](https://gianluca.statistica.it/teaching/intro-stats/)
]

---


# What is statistics all about?

- Typically, we observe some data and we want to use them to learn about some unobservable feature of the general population in which we are interested

- To do this, we use statistical models to describe the probabilistic mechanism by which (**we assume!**) that the data have arisen

&lt;center&gt;

&lt;center&gt;&lt;img src=./img/statistics-all-about-1.png width='85%' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;
&lt;/center&gt;

**NB**: Roman letters `\((y\)` or `\(x)\)` typically indicate **observable data**, while Greek letters `\((\theta\)`, `\(\mu\)`, `\(\sigma\)`, `\(\ldots)\)` indicate **population parameters**

---
exclude: true
# Sampling variability 
&lt;span style="display:block; margin-top: -20px ;"&gt;&lt;/span&gt;
### Probability calculus

&lt;center&gt;&lt;img src="img/prob_calculus.png" width="80%" title="Probability calculus is a process whereby we assume a known data generating process and we assess/propagate the sampling variability, e.g. the ways in which data can arise. From the entire population, we may enumerate all the possible ways of obtaining samples of a specific size"&gt;&lt;/center&gt;

---

exclude: true
# Sampling variability 
&lt;span style="display:block; margin-top: -20px ;"&gt;&lt;/span&gt;
### Statistics

&lt;center&gt;&lt;img src="img/statistics.png" width="80%" title="Statistics is essentially the inverse problem - we only have one observed dataset and based on the observations and some assumptions about the underlying data generating process, we want to infer some features of the parameters that characterise the underlying variability"&gt;&lt;/center&gt;

In reality we observe **only one** such sample (out of the many possible &amp;ndash; in fact there are **252** different ways of picking **at random** 5 units out of a population of size 10!) and we want to use the information contained in **that** sample to **infer** about the population parameters (e.g. the true mean and standard deviation)

---

background-image: url("img/Sherlock.png")
background-size: cover

# The Sherlock conundrum

---

# **Deductive** vs inductive inference


&lt;center&gt;&lt;img src=./img/goodman-1.png width='75%' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;
---

count: false
# **Deductive** vs inductive inference


&lt;center&gt;&lt;img src=./img/deduction1-1.png width='85%' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;

&lt;span style="display:block; margin-top: 2em ;"&gt;&lt;/span&gt;

- Standard (frequentist) procedures fix the working hypotheses and, **by deduction**, make inference on the observed data:
   - If my hypothesis is true, what is the probability of randomly selecting the data that I actually observed? If small, then *deduce* weak support of the evidence to the hypothesis
--

   - Assess `\(\Pr(\class{blue}{\style{font-family:inherit;}{\text{Observed data}}} \mid \class{orange}{\style{font-family:inherit;}{\text{Hypothesis}}})\)`
   - Directly relevant for standard frequentist summaries, eg p-values, Confidence Intervals, etc
   - **NB**: Comparison with data that could have been observed, but haven't!

&lt;span style="display:block; margin-top: 50px ;"&gt;&lt;/span&gt;
.small[
.alignright[
Adapted from &lt;svg viewBox="0 0 384 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  &lt;g label="icon" id="layer6" groupmode="layer"&gt;    &lt;path id="path2" d="M 120.19265,177.73779 C 123.18778,77.35076 64.277527,63.999998 64.277527,63.999998 v 31.26245 C 40.834519,83.611374 18.32863,81.929634 18.32863,81.929634 V 337.10903 c 0,0 98.10414,-11.41744 98.10414,84.40952 0,0 36.58424,-153.37442 248.86103,26.48145 0,-61.59342 0.37757,-216.93925 0.37757,-268.28471 C 169.9561,37.131382 120.1931,177.73779 120.1931,177.73779 Z m 187.20631,173.82056 -12.37599,-97.65441 h -0.448 l -40.72819,97.65441 h -17.55994 l -38.9362,-97.65441 h -0.448 l -14.17589,97.65441 h -43.87514 l 28.8015,-169.61925 h 43.42716 l 34.43518,90.6496 36.46566,-90.6496 h 43.87513 l 25.6817,169.61925 h -44.13938 z" style="stroke-width:0.0675239"&gt;&lt;/path&gt;  &lt;/g&gt;&lt;/svg&gt; [Goodman (1999)](https://pubmed.ncbi.nlm.nih.gov/10383371)
]
]

---

# Is there another way?...

&lt;center&gt;&lt;img src="img/brexit_bridge.jpg" width="65%"&gt;&lt;/center&gt;

---

# Deductive vs **inductive** inference


&lt;center&gt;&lt;img src=./img/induction1-1.png width='85%' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;

&lt;span style="display:block; margin-top: 2em ;"&gt;&lt;/span&gt;

- The **Bayesian** philosophy proceeds fixing the value of the observed data and, **by induction**, makes inference on unobservable hypotheses
   - What is the probability of my hypothesis, given the data I observed? If less than the probability of other competing hypotheses, then weak support of the evidence to the hypothesis
   
---

count: false
# Deductive vs **inductive** inference


&lt;center&gt;&lt;img src=./img/induction2-1.png width='85%' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;

&lt;span style="display:block; margin-top: 2em ;"&gt;&lt;/span&gt;

- The **Bayesian** philosophy proceeds fixing the value of the observed data and, **by induction**, makes inference on unobservable hypotheses
   - What is the probability of my hypothesis, given the data I observed? If less than the probability of other competing hypotheses, then weak support of the evidence to the hypothesis
   - Assess `\(\Pr(\color{#ff8811}{\style{font-family:inherit;}{\text{Hypothesis}}} \mid \color{#0000FF}{\style{font-family:inherit;}{\text{Observed data}}})\)`
   - Can express in terms of an **interval** estimate: `\(\Pr(a \leq \style{font-family:inherit;}{\text{parameter}} \leq b \mid \style{font-family:inherit;}{\text{Data}})\)`
   - **NB**: Unobserved data have no role in the inference!

---


# Bayesian inference 

## How did it all start?

In 1763, Reverend Thomas Bayes of Tunbridge Wells wrote

&lt;center&gt;&lt;img src=./img/bayes-quote.jpg width='650px' title='INCLUDE TEXT HERE'&gt;&lt;/center&gt;

In modern language, given `\(r \sim \style{font-family:inherit;}{\text{Binomial}}(\theta,n)\)`, what is
`\(\Pr( \theta_1 &lt; \theta &lt; \theta_2\mid r,n)\)`?

&lt;span style="display:block; margin-top: 3rem ;"&gt;&lt;/span&gt;

.content-box-beamer[

### Some historical references

&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  [ comment ]  &lt;path d="M503.52,241.48c-.12-1.56-.24-3.12-.24-4.68v-.12l-.36-4.68v-.12a245.86,245.86,0,0,0-7.32-41.15c0-.12,0-.12-.12-.24l-1.08-4c-.12-.24-.12-.48-.24-.6-.36-1.2-.72-2.52-1.08-3.72-.12-.24-.12-.6-.24-.84-.36-1.2-.72-2.4-1.08-3.48-.12-.36-.24-.6-.36-1-.36-1.2-.72-2.28-1.2-3.48l-.36-1.08c-.36-1.08-.84-2.28-1.2-3.36a8.27,8.27,0,0,0-.36-1c-.48-1.08-.84-2.28-1.32-3.36-.12-.24-.24-.6-.36-.84-.48-1.2-1-2.28-1.44-3.48,0-.12-.12-.24-.12-.36-1.56-3.84-3.24-7.68-5-11.4l-.36-.72c-.48-1-.84-1.8-1.32-2.64-.24-.48-.48-1.08-.72-1.56-.36-.84-.84-1.56-1.2-2.4-.36-.6-.6-1.2-1-1.8s-.84-1.44-1.2-2.28c-.36-.6-.72-1.32-1.08-1.92s-.84-1.44-1.2-2.16a18.07,18.07,0,0,0-1.2-2c-.36-.72-.84-1.32-1.2-2s-.84-1.32-1.2-2-.84-1.32-1.2-1.92-.84-1.44-1.32-2.16a15.63,15.63,0,0,0-1.2-1.8L463.2,119a15.63,15.63,0,0,0-1.2-1.8c-.48-.72-1.08-1.56-1.56-2.28-.36-.48-.72-1.08-1.08-1.56l-1.8-2.52c-.36-.48-.6-.84-1-1.32-1-1.32-1.8-2.52-2.76-3.72a248.76,248.76,0,0,0-23.51-26.64A186.82,186.82,0,0,0,412,62.46c-4-3.48-8.16-6.72-12.48-9.84a162.49,162.49,0,0,0-24.6-15.12c-2.4-1.32-4.8-2.52-7.2-3.72a254,254,0,0,0-55.43-19.56c-1.92-.36-3.84-.84-5.64-1.2h-.12c-1-.12-1.8-.36-2.76-.48a236.35,236.35,0,0,0-38-4H255.14a234.62,234.62,0,0,0-45.48,5c-33.59,7.08-63.23,21.24-82.91,39-1.08,1-1.92,1.68-2.4,2.16l-.48.48H124l-.12.12.12-.12a.12.12,0,0,0,.12-.12l-.12.12a.42.42,0,0,1,.24-.12c14.64-8.76,34.92-16,49.44-19.56l5.88-1.44c.36-.12.84-.12,1.2-.24,1.68-.36,3.36-.72,5.16-1.08.24,0,.6-.12.84-.12C250.94,20.94,319.34,40.14,367,85.61a171.49,171.49,0,0,1,26.88,32.76c30.36,49.2,27.48,111.11,3.84,147.59-34.44,53-111.35,71.27-159,24.84a84.19,84.19,0,0,1-25.56-59,74.05,74.05,0,0,1,6.24-31c1.68-3.84,13.08-25.67,18.24-24.59-13.08-2.76-37.55,2.64-54.71,28.19-15.36,22.92-14.52,58.2-5,83.28a132.85,132.85,0,0,1-12.12-39.24c-12.24-82.55,43.31-153,94.31-170.51-27.48-24-96.47-22.31-147.71,15.36-29.88,22-51.23,53.16-62.51,90.36,1.68-20.88,9.6-52.08,25.8-83.88-17.16,8.88-39,37-49.8,62.88-15.6,37.43-21,82.19-16.08,124.79.36,3.24.72,6.36,1.08,9.6,19.92,117.11,122,206.38,244.78,206.38C392.77,503.42,504,392.19,504,255,503.88,250.48,503.76,245.92,503.52,241.48Z"&gt;&lt;/path&gt;&lt;/svg&gt; [http://www.bayesian.org/resources/bayes.html](http://www.bayesian.org/resources/bayes.html)    
&lt;svg viewBox="0 0 448 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  [ comment ]  &lt;path d="M448 360V24c0-13.3-10.7-24-24-24H96C43 0 0 43 0 96v320c0 53 43 96 96 96h328c13.3 0 24-10.7 24-24v-16c0-7.5-3.5-14.3-8.9-18.7-4.2-15.4-4.2-59.3 0-74.7 5.4-4.3 8.9-11.1 8.9-18.6zM128 134c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm0 64c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm253.4 250H96c-17.7 0-32-14.3-32-32 0-17.6 14.4-32 32-32h285.4c-1.9 17.1-1.9 46.9 0 64z"&gt;&lt;/path&gt;&lt;/svg&gt; S. Bertsch McGrayne (2011). *[The Theory That Would Not Die](https://www.amazon.co.uk/Theory-That-Would-Not-Die/dp/0300188226)* .alignright[**see &lt;a href="..//#video"&gt;Lecture &lt;/a&gt;**]     
&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  &lt;g groupmode="layer" id="layer6" label="icon"&gt;    &lt;path style="stroke-width:0.07717" d="m 115.59247,222.50738 c -9.72601,0 -18.734334,7.07397 -24.986084,14.41694 -5.061076,5.95394 -7.591049,15.13238 -7.591049,22.77486 0,7.6402 2.870733,16.13879 7.931808,22.09274 6.152292,7.34297 12.778135,12.37522 22.603045,12.37522 8.83314,0 19.33786,-3.70766 25.389,-9.76105 6.1523,-6.05338 11.26931,-16.21737 11.26931,-25.04826 0,-8.73142 -2.39548,-19.18696 -8.54776,-25.24039 -6.15229,-6.15455 -17.33741,-11.61061 -26.06883,-11.61061 z m 174.6438,2.39944 c -10.12046,0 -18.35798,3.98058 -24.70919,11.93724 -5.15827,6.38628 -7.73967,13.66255 -7.73967,21.82831 0,8.27088 2.5814,15.59914 7.73967,21.98538 6.35064,7.95667 14.58873,11.93729 24.70919,11.93729 9.03149,0 16.67002,-3.25109 22.9212,-9.74241 6.25399,-6.59703 9.37846,-14.65259 9.37846,-24.18026 0,-9.422 -3.17646,-17.37639 -9.52708,-23.86775 -6.2495,-6.59477 -13.8428,-9.89721 -22.77258,-9.89721 z M 255.99998,7.9999981 C 119.03396,7.9999981 7.9999985,119.03394 7.9999985,255.99998 7.9999985,392.96602 119.03396,504 255.99998,504 392.96606,504 504,392.96602 504,255.99998 504,119.03394 392.96606,7.9999981 255.99998,7.9999981 Z M 197.17431,331.79065 h -45.93563 v -18.69931 c -4.66437,5.85506 -15.63869,11.82369 -20.40025,14.50172 -8.33473,4.66267 -19.65377,7.70067 -30.27265,7.70067 -17.167865,0 -32.44885,-5.425 -45.844653,-17.23173 -15.977193,-14.0903 -23.483472,-35.63322 -23.483472,-58.85447 0,-23.61798 8.186103,-42.47212 24.559999,-56.56242 12.999092,-11.21393 28.896046,-20.18949 45.766106,-20.18949 9.82264,0 21.93961,0.88269 30.57214,5.04865 4.96218,2.38076 13.84449,7.98548 19.10448,13.44381 v -98.50164 h 45.93564 v 229.34421 z m 157.21544,-21.13999 c -15.28099,17.58718 -36.66682,26.38303 -64.15348,26.38303 -27.58613,0 -49.01942,-8.79585 -64.30436,-26.38303 -12.60069,-14.44803 -18.90387,-32.19228 -18.90387,-53.23507 0,-18.94908 6.35065,-35.75132 19.0525,-50.4079 15.37988,-17.69285 37.26185,-26.54011 65.64139,-26.54011 26.09766,0 46.93585,8.84558 62.51694,26.54011 12.70185,14.44806 19.05247,31.66734 19.05247,51.66468 0.003,20.20586 -6.29921,37.53085 -18.90159,51.97886 z m 38.76899,-199.21794 c 5.35888,-5.35888 11.85868,-8.03746 19.49892,-8.03746 7.64024,0 14.14005,2.67858 19.49893,8.03746 5.35888,5.25945 8.03746,11.70955 8.03746,19.35034 0,7.73965 -2.67858,14.28864 -8.03746,19.64753 -5.25944,5.25944 -11.75925,7.8883 -19.49893,7.8883 -7.64247,0 -14.14227,-2.67861 -19.49892,-8.0375 -5.2594,-5.35885 -7.88829,-11.85871 -7.88829,-19.49892 -0.003,-7.6402 2.62889,-14.0903 7.88829,-19.35029 z m 43.91029,220.24265 H 388.24626 V 185.84118 h 48.82277 z" id="path2"&gt;&lt;/path&gt;  &lt;/g&gt;&lt;/svg&gt; S. Fienberg (2006). [When did Bayesian inference become Bayesian?](doi:10.1214/06-BA101)
]

---

count: false
# Bayesian inference

## Basic ideas

### Direct expression of uncertainty about unknown parameters

&lt;span style="display:block; margin-top: -10px ;"&gt;&lt;/span&gt;
.content-box-lightblue[
"There is an 89% probability that the absolute increase in major bleeds is less than 10 percent with low-dose PLT 
transfusions"  .small[.alignright[(&lt;svg viewBox="0 0 384 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  &lt;g label="icon" id="layer6" groupmode="layer"&gt;    &lt;path id="path2" d="M 120.19265,177.73779 C 123.18778,77.35076 64.277527,63.999998 64.277527,63.999998 v 31.26245 C 40.834519,83.611374 18.32863,81.929634 18.32863,81.929634 V 337.10903 c 0,0 98.10414,-11.41744 98.10414,84.40952 0,0 36.58424,-153.37442 248.86103,26.48145 0,-61.59342 0.37757,-216.93925 0.37757,-268.28471 C 169.9561,37.131382 120.1931,177.73779 120.1931,177.73779 Z m 187.20631,173.82056 -12.37599,-97.65441 h -0.448 l -40.72819,97.65441 h -17.55994 l -38.9362,-97.65441 h -0.448 l -14.17589,97.65441 h -43.87514 l 28.8015,-169.61925 h 43.42716 l 34.43518,90.6496 36.46566,-90.6496 h 43.87513 l 25.6817,169.61925 h -44.13938 z" style="stroke-width:0.0675239"&gt;&lt;/path&gt;  &lt;/g&gt;&lt;/svg&gt; [Tinmouth et al, *Transfusion*, 2004](https://pubmed.ncbi.nlm.nih.gov/15584985))]]]

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;
&lt;img src="./img/unnamed-chunk-2-1.png" style="display: block; margin: auto;" width="40%" title="The graph shows the distribution of the % absolute increase in risk, given the observed data. As most of this distribution is below 10%, then we can conclude that the risk is limited"&gt;

---

count: false
# Bayesian inference 

## Basic ideas

&lt;img src="./img/unnamed-chunk-3-1.png" style="display: block; margin: auto;" width="30%" fig.align="center" title="An example of a diagnostic problem. If we do not consider the 'background prevalence' of the disease, we get an incomplete picture. Bayes theorem allows us to account of this information formally"&gt;

- Suppose a patient is tested for HIV. The test comes up negative (&amp;ndash;ve)

- Given the assumptions/model, this indicates **fairly strong** evidence against the hypothesis that the true status is "Disease", so basically `\(p=0.04\)`

---
count: false
# Bayesian inference

## Basic ideas

&lt;img src="./img/unnamed-chunk-4-1.png" style="display: block; margin: auto;" width="30%" fig.align="center" title="An example of a diagnostic problem. If we do not consider the 'background prevalence' of the disease, we get an incomplete picture. Bayes theorem allows us to account of this information formally"&gt;

- Suppose a patient is tested for HIV. The test comes up negative (&amp;ndash;ve)

- Given the assumptions/model, this indicates **fairly strong** evidence against the hypothesis that the true status is "Disease", so basically `\(p=0.04\)`

- But: how **prevalent** is the disease in the population?
  - We can model our prior knowledge about this and combine this information with the evidence from the data (using **Bayes theorem**)

&lt;span style="display:block; margin-top: -20px ;"&gt;&lt;/span&gt;
$$ \Pr(\style{font-family:inherit;}{\text{Disease}} \mid \style{font-family:inherit;}{\text{-ve}}) = \frac{\Pr(\style{font-family:inherit;}{\text{Disease}})\Pr(\style{font-family:inherit;}{\text{-ve}} \mid \style{font-family:inherit;}{\text{Disease}})}{\Pr(\style{font-family:inherit;}{\text{-ve}})} $$

- Update uncertainty given the evidence provided by the data

---

# Bayesian inference  

## Prior vs posterior

- The evidence **from the data alone** tells us that the observed result is extremely unlikely under the hypothesis of "Disease"
- This is strongly dependent on the **context**, as provided by the prior knowledge/epistemic uncertainty, though!

&lt;img src="./img/unnamed-chunk-5-1.png" style="display: block; margin: auto;" width="35%" title="The posterior distribution can depend strongly on the value assumed for the prior. In general, if the prior is too strong (for example, if you assume that no-one has the disease in the first place), then the posterior will be completely driven by it. In this example, if the prior prevalence of the disease is 80%, then the posterior after observing a negative test is only about 14% chance of being infected"&gt;

---

count: false
# Bayesian inference 

## Basic ideas

- A Bayesian model specifies a **full probability distribution** to describe uncertainty

- This applies to    
   - **Data**, which are subject to **sampling variability**
   - **Parameters** (or hypotheses), typically unobservable and thus subject to **epistemic uncertainty**
   - And even future, yet unobserved realisations of the observable variables (data) 
--


- Probability is the only languange in the Bayesian framework to assess any form of imperfect information or knowledge
   - No need to distinguish between probability and confidence
   - Before even seeing the data, we need to identify a suitable probability distribution to describe the overall uncertainty about the data `\(\boldsymbol{y}\)` and the parameters `\(\boldsymbol\theta\)`
   
--

$$ p(\boldsymbol{y},\boldsymbol\theta)=p(\boldsymbol\theta)p(\boldsymbol y\mid\boldsymbol\theta) = p(\boldsymbol y)p(\boldsymbol\theta\mid \boldsymbol y) $$
&amp;emsp; (see also &lt;a href="../04_ILD/#factorisation"&gt;Lecture 4&lt;/a&gt;) from which we derive Bayes Theorem
   
$$ p(\boldsymbol\theta\mid \boldsymbol y) = \frac{p(\boldsymbol\theta)p(\boldsymbol y\mid\boldsymbol\theta)}{p(\boldsymbol y)} $$

- **Express beliefs in form of a probability distribution**

---

exclude: true
# Bayesian modelling

## (Super) silly example: drug

.pull-left[
**Existing knowledge**
- Population registries
- Observational studies
- Small/pilot RCTs
- Expert opinion
]
.pull-right[
]

&lt;span style="display:block; margin-top: -60px ;"&gt;&lt;/span&gt;
&lt;img src="./img/unnamed-chunk-6-1.png" style="display: block; margin: auto;" width="33%" title="The prior distribution shows the 'state of science' about the relevant model parameters before any new data are observed"&gt;
Encode the assumption that a drug has a response rate between 20% and 60%

---

exclude: true
count: false
# Bayesian modelling

## (Super) silly example: drug
.pull-left[
**Existing knowledge**
- Population registries
- Observational studies
- Small/pilot RCTs
- Expert opinion
]
.pull-right[
.alignright[
**Current data**
- Large(r) scale RCT
- Observational study
- Relevant summaries
]
]

&lt;span style="display:block; margin-top: -60px ;"&gt;&lt;/span&gt;
&lt;img src="./img/unnamed-chunk-7-1.png" style="display: block; margin: auto;" width="33%" title="The evidence provided by the actual data under the current modelling assumptions can be represented by the likelihood function. Note that the sampling distribution is a function of the data for a fixed value of the parameters, so it would not be directly comparable with the prior. However, we can consider the likelihood function (which depends on the unknown model parameters, given fixed value of the data), which is defined on the same scale of the prior and the posterior"&gt;
Observe a study with 150 responders out of 200 patients given the drug

---

exclude: true
count: false
# Bayesian modelling 

## (Super) silly example: drug

.pull-left[
**Existing knowledge**
- Population registries
- Observational studies
- Small/pilot RCTs
- Expert opinion
]
.pull-right[
.alignright[
**Current data**
- Large(r) scale RCT
- Observational study
- Relevant summaries
]
]

&lt;span style="display:block; margin-top: -60px ;"&gt;&lt;/span&gt;
&lt;img src="./img/unnamed-chunk-8-1.png" style="display: block; margin: auto;" width="33%" title="The posterior distribution is generally a compromise between the prior and the likelihood. The more definitive the evidence provided by the data (and hence the likelihood), the closer the posterior to the likelihood function"&gt;
Update knowledge to describe revised "state of science"

---

exclude: true
# .small[*But how can I form a prior? I know **nothing** about this parameter!*...]

---

exclude: true
count: false
# .small[*But how can I form a prior? I know **nothing** about this parameter!*...]

&lt;center&gt;&lt;img src="img/Silvio.jpg" background-size: contain; title="This is an example about statistical modelling of political data. I am personally very interested in politics and, as an Italian, at some point I became fed up with my country, who decided that having Berlusconi as prime minister was a good idea. US President Obama's look while Berlusconi checks out the US First Lady is a good summary of my own opinion of the Italian PM...";&gt;&lt;/center&gt;

---

exclude: true
count: false
# .small[*But how can I form a prior? I know **nothing** about this parameter!*...]

.pull-left[
&lt;center&gt;&lt;img src="img/chips.jpg" background-size: contain; title="So when I moved to the UK I was for a while reassured that I was living in a saner country. Until they also decided that somebody like Ms May was a good idea for a PM...";&gt;&lt;/center&gt;
]

--

exclude: true
.pull-right[
&lt;center&gt;&lt;img src="img/ohdeargod.jpg" background-size: contain; title="And imagine my despair when they also decided that somebody like Mr Johnson was an even better idea for PM...";&gt;&lt;/center&gt;
]

---

exclude: true
count: false
# .small[*But how can I form a prior? I know **nothing** about this parameter!*...]

- Predicting the output of the 2017 UK General Election using poll data (see [here](https://gianluca.statistica.it/post/2017-04-25-snap/) and subsequent posts)
  - Data: number of people out of the `\(N_i\)` respondents in poll `\(i\)` intending to vote for party `\(p\)` (multinomial counts)    
  - **Objective of estimation**: `\((\pi_1,\ldots,\pi_P)=\)` population vote share for each party    
  - Can model `\(\pi_p = \left(\phi_p\middle / \sum \phi_p \right)\)` and `\(\displaystyle \log(\phi_p) = \alpha_p + \beta_p X_p\)`

&lt;center&gt;&lt;img src="img/Election.png" width="40%" title="Anyway, the point is that we do have some knowledge about the thing we want to model in the first place... In the election example, we can pretend that we don't know anything, but this would actually mean that we would assume, before observing any data, that all the parties have more or less the same share of the vote. This is clearly not true (if anything based on the last election and the current parliament composition) and so we should encode this knowledge in our model"&gt;&lt;/center&gt;

&lt;span style="display:block; margin-top: -2em ;"&gt;&lt;/span&gt;
.small[.alignright[&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  [ comment ]  &lt;path d="M256 8c137 0 248 111 248 248S393 504 256 504 8 393 8 256 119 8 256 8zm-28.9 143.6l75.5 72.4H120c-13.3 0-24 10.7-24 24v16c0 13.3 10.7 24 24 24h182.6l-75.5 72.4c-9.7 9.3-9.9 24.8-.4 34.3l11 10.9c9.4 9.4 24.6 9.4 33.9 0L404.3 273c9.4-9.4 9.4-24.6 0-33.9L271.6 106.3c-9.4-9.4-24.6-9.4-33.9 0l-11 10.9c-9.5 9.6-9.3 25.1.4 34.4z"&gt;&lt;/path&gt;&lt;/svg&gt; [Next lecture](../02_BUGS/index.html)]]

---

&lt;!-- LECTURE 2 --&gt;

# Bayesian computation

.pull-left[
In artificially simplified modelling structures, Bayesian computations are just as easy as "standard" statistical models
   
- [Thomas Bayes](https://youtu.be/-e8wOcaascM) (1763) .alignright[üëâ] 
   - Set up (what we now call) a Binomial model for number of "successes" out of a set number of "trials"
   - Applied to billiard balls:  
   
- Pierre-Simon Laplace (1786)
   - Analysed data on christening in Paris from 1745 to 1770 using (what we now consider) a Bayesian model
   - Concludes that he was "morally certain" that `\(\Pr(\style{font-family:inherit;}{\text{new born is boy}}\mid \style{font-family:inherit;}{\text{data}}) \geq 0.5\)` (divine providence to account for the fact that males died at higher rates...)
]

.pull-right[
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/lAdSpsJ0vxk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;
]

---

count: false
name: video
# Bayesian computation

.pull-left[
But they can become very complicated in realistic models

- Alan Turing (1940s): [breaking the Enigma code](https://youtu.be/oTltncUkckQ) .alignright[üëâ] 
   - Using "prior" information and guess a stretch of letters in an Enigma message, measure their belief in the validity of these guesses and more clues as they arrived
       
Since the 1990s, rely on computer simulations and a suite of algorithms called **Markov Chain Monte Carlo** (MCMC)

- Highly generalisable, can throw at it virtually any complexity

- Can still be computationally intensive, but variants of "vanilla" implementations can be made **very** efficient
]
.pull-right[
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/oTltncUkckQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;
]

--

&lt;span style="display:block; margin-top: 20px ;"&gt;&lt;/span&gt;

Need to manipulate probability distributions to express both .red[**sampling variability**] and .olive[**epistemic uncertainty**]!

- Choose most appropriate distribution for the quantity of interest


---

# Beta distribution

General distribution representing uncertainty about a *proportion* or *probability* - values between *0 and 1*

.pull-left[
&lt;img src="./img/unnamed-chunk-9-1.png" style="display: block; margin: auto;" title="A Beta distribution is extremely versatile to represent uncertainty on quantites defined in the range 0-1. Upon varying the parameters of the distribution, we can get very different shapes indicating different levels of knowledge or uncertainty about the underlying value of the variable modelled using the Beta distribution" width="95%" dev="tikz"&gt;
]

.pull-right[.center-right[
`\(\theta \sim \style{font-family:inherit;}{\text{Beta}}(a,b)\)` has density
$$ p(\theta\mid a, b) = \frac{\Gamma(a+ b)}{ \Gamma(a)\Gamma(b) } \,\,\theta^{a-1}  (1-\theta)^{b-1} $$
Mean and variance:
\begin{align} 
\mu &amp; =\frac{a}{a+ b }  \\\\
\sigma^2 &amp;=  \frac{a b}{ (a+ b)^2 (a+ b+1)}
\end{align}   
]
]

---

count: false
name: beta-tricks
# Beta distribution

## Expressing beliefs as a Beta distribution

1. Define mean and SD

   - `\(\style{font-family:inherit;}{\text{Beta}}(a,b)\)` has mean `\(\displaystyle \mu = \frac{a}{a+b}\)`, variance `\(\displaystyle \sigma^2 = \frac{ab}{(a+b)^2(a+b+1)}\)`
   - Solving gives `\(a,b\)` in terms of assumed mean and SD:
   $$ a = \mu\left(\frac{(1 - \mu)\mu}{\sigma^2} - 1\right)$$
   $$ b = (1 - \mu)\left(\frac{(1 - \mu)\mu}{\sigma^2} - 1\right )$$
   eg mean 0.4, sd 0.1 gives Beta(9.2, 13.8)
  
--

2. Use an *implicit* dataset
   - Imagine your beliefs about the success rate `\(p\)` are equivalent to observing, e.g. `\(y_0=8\)` successes out of `\(n_0=20\)` trials
   - This gives about `\(\style{font-family:inherit;}{\text{Beta}}(y_0+1, n_0-y_0+1)\)` &amp;ndash; see &lt;a href="../02_MCMC/#conjugacy"&gt;Lecture 2&lt;/a&gt; for theory!
   - Mean `\((y_0+1)/(n_0+2) \approx 0.4\)` and SD `\(\approx 0.1\)` here
   
---

count: false
# Beta distribution

.pull-left[
&lt;img src="./img/unnamed-chunk-10-1.png" style="display: block; margin: auto;" title="Again, changing the values for the parameters a and b does modify the shape of the underlying Beta distribution. If we select a=20 and b=25, this is essentially equivalent to assuming a thought experiment that represents our uncertainty before seeing any data to a trial with 25 people of whom 25 experienced the event under consideration. The shape of the distribution is similar if we consider a=200 and b=250 (same as before but 10 times bigger). This is because we're now considering a prior based on an experiment with 200 'successes' out of 250 trials. So the underlying proportion of successes is the same (20/25=200/250), but we are now more confident, because we pretend to have observed 10 times as many people. This explains why the Beta(1,1) indicates complete ignorance - because it is akin to a thought experiment with 0 successes out of 0 trials"&gt;
]

.pull-right[

```r
&gt; # Sets prior "successes" and "trials" 
&gt; y=20; n=25
&gt; 
&gt; # Computes the mean of the distribution
&gt; mean(rbeta(1000000,y+1,n-y+1))
```

```
[1] 0.7778048
```

```r
&gt; # Computes summary statistics 
&gt; cbind("2.5%"=qbeta(.025,y+1,n-y+1),
+       "median"=qbeta(.5,y+1,n-y+1),
+       "97.5%"=qbeta(.975,y+1,n-y+1))
```

```
          2.5%    median     97.5%
[1,] 0.6064945 0.7847057 0.9102599
```


**NB**: `\(y_0=n_0=0 \Rightarrow\)` "complete ignorance" *non-informative* prior &amp;ndash; Beta(1,1) = Uniform(0,1)
]

---

name: gamma-distribution
# Gamma distribution

*Positive*, skewed quantities (eg costs, variance parameters)

.pull-left[
&lt;img src="./img/unnamed-chunk-12-1.png" style="display: block; margin: auto;" width="95%" title="A Gamma is a skewed, positive distribution with two parameters a and b. Like for the Beta, changing their values gives us different shapes"&gt;
]

.pull-right[.center-right[
If `\(Y \sim \style{font-family:inherit;}{\text{Gamma}}(a,b)\)`

`\begin{align}
p(y\mid a, b) &amp; = \frac{ b^a }{\Gamma(a) } y^{a-1} \; e^{-by}   \\\\
{\rm E}(Y \mid a, b) &amp;= \frac{a}{ b }\\\\
{\rm V}(Y \mid a, b) &amp;= \frac{a}{ b^2 }
\end{align}`


&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;position:relative;display:inline-block;top:.1em;fill:blue;"&gt;  [ comment ]  &lt;path d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"&gt;&lt;/path&gt;&lt;/svg&gt; log-Normal distribution is similar (but heavier tails than Gamma &amp;ndash; see also &lt;a href="../04_ILD/#gamma-lognormal"&gt;Lecture 4&lt;/a&gt;!)
]
]

---

# *Doing* Bayesian analysis

## Broadly speaking, there are two types of Bayesian analysis:

**Forward sampling**  (Monte Carlo): this lecture
- Express current knowledge as parameters with distributions     
- Simulate parameters, make predictions from models based on the parameters     
- Like a spreadsheet with randomness on cells. Familiar in health economics as "probabilistic sensitivity analysis" (**see &lt;a href="../03_Intro_HE/index.html"&gt;Lecture 3&lt;/a&gt;**)    
- Doesn't really need specialised software

--

&lt;span style="display:block; margin-top: 2em ;"&gt;&lt;/span&gt;

**Model fitting** using Bayes Theorem (Markov Chain Monte Carlo): **see &lt;a href="../02_MCMC/index.html"&gt;Lecture 2&lt;/a&gt;** 
- Combine prior knowledge with *learning from data*    
- Searches for the unknown *posterior* distribution based on prior and data    
- Needs to use/programme specific software (eg `BUGS`)

---

count: false
# *Doing* Bayesian analysis

## The `BUGS` language

### `B`**ayesian analysis** `U`**sing** `G`**ibbs** `S`**ampling**

- Language for specifying Bayesian models as a *network* of *known and unknown* quantities


.pull-left[
eg linear regression
`\begin{align}
Y_i &amp; \sim \style{font-family:inherit;}{\text{Normal}}(\mu_i, \tau)\\
\mu_i &amp; = \alpha + \beta x_i\\
\tau &amp; = 1 / \sigma^2
\end{align}`


```r
for (i in 1:N) {
  Y[i] ~ dnorm(mu[i], tau)
  mu[i] &lt;- alpha + beta*x[i]
}
tau &lt;- 1/(sigma*sigma)

# Prior knowledge 
alpha ...
beta ...
sigma ...
)
```
]

.pull-right[
Works by internally constructing *directed acyclic graph* - model code *equivalent* to a graph

&lt;center&gt;&lt;img src="img/line.png" width="650"&gt;&lt;/center&gt;

Simulates distributions of unknowns conditional on prior distributions and data
]

---

count: false
# *Doing* Bayesian analysis 

### Different versions of `BUGS` 

- `WinBUGS` 1.4.3 
   - Original release 1997 &amp;ndash; runs only on `Windows`
   - Stable but no longer developed (latest release: August 2007)
   - Freely available from &lt;img src="img/WinBUGSlogo.jpg"; width="15"&gt; [http://www.mrc-bsu.cam.ac.uk/bugs](http://www.mrc-bsu.cam.ac.uk/bugs)

- `OpenBUGS` &lt;img src="img/openbugs.jpg"; width="15"&gt; [http://www.openbugs.net](http://www.openbugs.net) 
   - Open-source offshoot, also runs on `Linux` and `MacOS`
   - Works just as well, stable

--

### "Rivals"/alternatives 

- `JAGS` [http://mcmc-jags.sourceforge.net](http://mcmc-jags.sourceforge.net) 
   - Language essentially identical, Work just as well, stable 
   - Runs natively on `Mac`/`Unix`/`Windows`

- `Stan` &lt;img src="img/stan_logo.png"; width="15"&gt; [http://mc-stan.org/](http://mc-stan.org/)
   - *Probabilistic* language &amp;ndash; slightly different than `BUGS`/`JAGS`
   - Based on different algorithm &amp;ndash; can be more efficient in some cases


Interfaces exist to run these from other software, eg &lt;svg viewBox="0 0 581 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  [ comment ]  &lt;path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"&gt;&lt;/path&gt;&lt;/svg&gt;  ([`R2OpenBUGS`](https://cran.r-project.org/web/packages/R2OpenBUGS/R2OpenBUGS.pdf), [`R2jags`](https://cran.r-project.org/web/packages/R2jags/R2jags.pdf), [`rstan`](https://cran.r-project.org/web/packages/rstan/rstan.pdf)) `Excel`, `S-Plus`, `SAS`, `Matlab`, `Stata`, ...


---

count: false
# *Doing* Bayesian analysis 

## A Bayesian workflow...

1. Pre-process data

   - Import dataset from spreadsheet
   - Create new variables
   - Subset data
   - ...

--

2. Sets up model
   - Code up distributional assumptions
   - Define initial values (**more on this in &lt;a href="../02_MCMC/index.html"&gt;Lecture 2&lt;/a&gt;!**)

--

3.  "Run" the model and obtain simulations from the target (posterior) distributions
   - Typically done using "Gibbs Sampling" (eg `BUGS`)
   - But other engines/MCMC algorithms/approximation methods available

--

4. Use simulations to summarise results
   - Make histograms of target (posterior) distributions
   - Compute means, sd, medians, quantiles of target (posterior) distributions
   - Derive distributions for functions of original parameters `\(g(\theta)\)` &amp;ndash; **more on this in &lt;a href="../05_ALD/index.html"&gt;Lecture 5&lt;/a&gt;!** 
   
---

# Some aspects of the `BUGS` language

Not a conventional programming language 

- `BUGS` is for *describing a model*
   - ***not*** for performing a sequence of tasks in order

- Every line defines a model quantity in relation to others  

&gt; ### Random (stochastic) dependence
&gt;
&gt; e.g.:  &lt;tt style = "font-family:inconsolata; color: #143455;"&gt;r ~ dunif(a,b)&lt;/tt&gt; 

- Simulate data `\(r\)` from model, or fit model to observed data `\(r\)`

&gt; ### Fixed (logical) dependence
&gt;
&gt; e.g.: &lt;tt style = "font-family:inconsolata; color: #143455;"&gt;m &lt;- a + b*x&lt;/tt&gt;

- Define any quantity as deterministic function of another (as in a spreadsheet)

---

# Functions in the `BUGS` language

Use in definitions of logical quantities, eg mathematical functions

- .red[`tau &lt;- 1 / pow(s,2)`] sets `\(\tau = 1/s^2\)`
- .red[`s   &lt;- 1 / sqrt(tau)`] sets `\(s = 1/\sqrt{\tau}\)`

Useful data processing tricks, eg
- .red[`p &lt;- step(x - 0.7)`]  = 1 if `x` `\(\ge\)` 0.7, 0 otherwise. Hence monitoring `p` and recording its mean will give the
probability that `x` `\(\ge\)` 0.7
- .red[`p &lt;- equals(x, 0.7)`]  = 1 if `x` `\(=\)` 0.7, 0 otherwise


See "Model Specification/Logical nodes" in manual for full syntax

---

# Some common distributions

&lt;table class=" lightable-classic table" style='font-family: "Arial Narrow", "Source Sans Pro", sans-serif; margin-left: auto; margin-right: auto; width: auto !important; margin-left: auto; margin-right: auto;'&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;font-weight: bold;border-top: 2px solid;"&gt; Expression &lt;/th&gt;
   &lt;th style="text-align:left;font-weight: bold;border-top: 2px solid;"&gt; Distribution &lt;/th&gt;
   &lt;th style="text-align:left;font-weight: bold;border-top: 2px solid;"&gt; Usage &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-family: 'Inconsolata';"&gt; dbin &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Binomial &lt;/td&gt;
   &lt;td style="text-align:left;font-family: 'Inconsolata';"&gt; r ~ dbin(p, n) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-family: 'Inconsolata';"&gt; dnorm &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Normal &lt;/td&gt;
   &lt;td style="text-align:left;font-family: 'Inconsolata';"&gt; x ~ dnorm(mu, tau) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-family: 'Inconsolata';"&gt; dpois &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Poisson &lt;/td&gt;
   &lt;td style="text-align:left;font-family: 'Inconsolata';"&gt; r ~ dpois(lambda) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-family: 'Inconsolata';"&gt; dunif &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Uniform &lt;/td&gt;
   &lt;td style="text-align:left;font-family: 'Inconsolata';"&gt; x ~ dunif(a, b) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;font-family: 'Inconsolata';border-bottom: 2px solid;"&gt; dgamma &lt;/td&gt;
   &lt;td style="text-align:left;border-bottom: 2px solid;"&gt; Gamma &lt;/td&gt;
   &lt;td style="text-align:left;font-family: 'Inconsolata';border-bottom: 2px solid;"&gt; x ~ dgamma(a, b) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;span style="display:block; margin-top: 1em ;"&gt;&lt;/span&gt;

- **NB**: The normal is parameterised in terms of its mean and ***precision*** = 1/ variance = `\(1/\sd^2\)` 

- Functions cannot be used as arguments in distributions (you need to create new nodes)

See "Model Specification/The `BUGS` language: stochastic nodes/Distributions" in manual for full syntax

---

# Arrays and loops in `BUGS`

Use arrays and loops for sets of related quantities


```r
for (i in 1:n) {
  r[i] ~ dbin(p[i],n[i])
  p[i] ~ dunif(0,1)
}
```

Array functions: eg `mean(p[])` to take mean of whole array, `mean(p[m:n])` to take mean of elements `m` to `n`.  Similarly, `sum(p[])`


See "Hints on using `OpenBUGS`" handouts, or the `OpenBUGS` manual for full information or `BUGS` syntax

---

# Forward sampling

- Consider a drug to be given for relief of chronic pain
- Experience with similar compounds has suggested that annual response rates between 0.2 and 0.6 could be feasible
- Interpret this as a distribution with mean = 0.4 and standard deviation = 0.1

&lt;img src="./img/unnamed-chunk-16-1.png" style="display: block; margin: auto;" width="48%" title="A Beta with parameters a=9.2 and b=13.8 encodes the assumption that the mean is about 0.4 and that most of the distribution is included in the interval between 0.2 and 0.6"&gt;

A **.red[Beta(9.2,13.8)]** distribution has these properties 

---

count: false
# Forward sampling 
&lt;span style="display:block; margin-top: -20px ;"&gt;&lt;/span&gt;
### Prior *knowledge* vs prior *distribution*

- Consider a drug to be given for relief of chronic pain
- Experience with similar compounds has suggested that annual response rates between 0.2 and 0.6 could be feasible
- Interpret this as a distribution with mean = 0.4 and standard deviation = 0.1

&lt;img src="./img/unnamed-chunk-17-1.png" style="display: block; margin: auto;" width="48%" title="But a Normal distribution with parameters mean=-0.40 and sd=0.41, when rescaled on the logit scale, encodes pretty much the exact same information!"&gt;

**But**: there are many possible ways to encode this prior information. For example, one could use a **.red[Normal distribution on the logit scale]**!

---

# Forward sampling

## Making predictions

1. Model sampling variability of `\(y\mid\theta\)` and uncertainty on `\(\theta\)`
2. **Propagate** uncertainty in the success rate `\(\theta\)`
3. Compute the *.red[predictive]* distribution of `\(y\)`: averaged over uncertainty about `\(\theta\)`

.myblue[$$p(y) = \int p(y\mid\theta) p (\theta) d\theta$$]

--

For instance, we can model 
- `\(y\mid \theta\sim \style{font-family:inherit;}{\text{Binomial}}(\theta,n)\)`: "natural" model for sampling variability
- `\(\theta \sim \style{font-family:inherit;}{\text{Beta}}(a,b)\)`: convenient model for epistemic uncertainty

In `BUGS`:

```r
model {
  theta ~ dbeta(a, b)
  y ~ dbin(theta, n)
}
```

---

count: false 

# Forward sampling .subtitle[Making predictions]

.panelset[
.panel[
.panel-name[`R` Code]

```r
&gt; # Sets up the parameters for the Beta prior
&gt; a=9.2
&gt; b=13.8
&gt; 
&gt; # Then simulates 1000 random samples from the prior
&gt; theta=rbeta(n=10000,a,b)
&gt; 
&gt; # Now "mixes" **uncertainty** in the value of the parameter 
&gt; # with **variability** in the data sampling distribution
&gt; y=rbinom(n=10000,size=20,prob=theta)
```
]
.panel[
.panel-name[Output]
.pull-left[
&lt;img src="./img/unnamed-chunk-20-1.png" style="display: block; margin: auto;" width="90%" title="The prior distribution is defined on the scale of the parameter, so in this case the range 0-1 (because the parameter is a probability of success)"&gt;
]
.pull-right[
&lt;img src="./img/unnamed-chunk-21-1.png" style="display: block; margin: auto;" width="90%" title="The predictive distribution is defined on the scale of the actual data (in this case the positive integers up to 20)"&gt;
]

(a) is the Beta (prior) distribution 

(b) is the predictive **.olive[Beta-Binomial]** distribution of the number of successes in the next 20 trials
]
]

---

exclude: true

# Forward sampling .subtitle[Making predictions]

.pull-left[
&lt;img src="./img/unnamed-chunk-22-1.png" style="display: block; margin: auto;" width="85%" title="INSERT TEXT HERE"&gt;
]
.pull-right[
&lt;img src="./img/unnamed-chunk-23-1.png" style="display: block; margin: auto;" width="85%" title="INSERT TEXT HERE"&gt;
]


(a) is the Beta (prior) distribution for `\(\theta\)`

(b) is the predictive **.olive[Beta-Binomial]** distribution of the number of successes `\(y\)` in the next 20 trials

---

# Forward sampling 

## Using MC to estimate tail area probabilities

- What is the chance of getting 15 or more responders?
   - `\(\theta \sim \style{font-family:inherit;}{\text{Beta}}(9.2, 13.8)\)`: prior distribution
   
   - `\(y \sim \style{font-family:inherit;}{\text{Binomial}}(\theta, 20)\)`: sampling distribution
   
   - `\(P_{\rm crit} = \Pr(y \ge 15)\)`: probability of exceeding critical threshold


--

- In `BUGS` can code by translating the equations

```r
# In BUGS syntax
 model {
   theta ~ dbeta(9.2, 13.8)   # prior distribution
   y ~ dbin(theta, 20)        # sampling distribution
   P.crit &lt;- step(y - 14.5)   # = 1 if y &gt;=15, 0 otherwise
 }
```

- **NB**: in `BUGS`, statements can be given in any order!

---

# Forward sampling 

## `OpenBUGS` output and exact answer


```r
 node     mean    sd     MC error    2.5%    median  97.5% start sample
 theta   0.4008  0.09999 9.415E-4    0.2174  0.3981  0.6044  1   10000
 y       8.058   2.917   0.03035     3.0     8.0     14.0    1   10000
 P.crit  0.0151  0.122   0.001275    0.0     0.0     0.0     1   10000
```

**NB**: Mean of the 0-1 indicator `P.crit`: estimated tail-area probability

Exact answers from closed-form algebra:
- `\(\theta\)`:  mean 0.4 and standard deviation  0.1
- `\(y\)`:       mean 8 and standard deviation  2.92
-  Probability of at least 15:  0.015

MC error `\(\approx\)` `\(\style{font-family:inherit;}{\text{sd}}/\sqrt{\style{font-family:inherit;}{\text{No. iterations}}}\)` = std. error for *estimate of* mean

Can achieve arbitrary accuracy by running the simulation for longer

---

# Forward sampling 

## `OpenBUGS` output

&lt;center&gt;&lt;img src=./img/drug-MC.png width='650' title='The BUGS output can show different metrics to assess the results, including traceplots (more on this in the next lecture) and histograms or densities for the relevant quantities'&gt;&lt;/center&gt;

Independent samples, so no concern with convergence (More on this later...)

---

# `OpenBUGS` script

## Drug: Monte Carlo example

Run from `Model/Script` menu
.small[

```r
modelDisplay('log')                      # set up log file
modelCheck('c:/bugscourse/drug-MC')      # check syntax of model
#  modelData('c:/bugscourse/drug-data')  # load data file if there is one
modelCompile(1)                          # generate code for 1 simulations
# modelInits('c:/bugscourse/drug-in1',1) # load initial values if necessary
modelGenInits()                          # generate initial values for all unknown 
                                         # quantities not given initial values
samplesSet(theta)                        # monitor the true response rate
samplesSet(y)                            # monitor predicted number of successes
samplesSet(P.crit)                       # monitor whether a critical number of successes
samplesTrace("*")                        # watch some simulated values (NB: slows simulation!)
modelUpdate(10000)                       # perform 10000 simulations
samplesHistory(theta)                    # Trace plot of samples for theta
samplesStats("*")                        # Summary statistics for all monitored quantities
samplesDensity(theta)                    # Plot distribution of theta
samplesDensity(y)                        # Plot distribution of y
```
]

Automates mouse clicks: important analyses should be *.red[repeatable]* (**But** effectively superseded by more effective tools, eg `R2OpenBUGS`!)


.small[(warning: script commands different between `OpenBUGS` and `WinBUGS`)]

.small[.alignright[&lt;svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" style="height:1em;fill:currentColor;position:relative;display:inline-block;top:.1em;"&gt;  [ comment ]  &lt;path d="M256 8c137 0 248 111 248 248S393 504 256 504 8 393 8 256 119 8 256 8zm-28.9 143.6l75.5 72.4H120c-13.3 0-24 10.7-24 24v16c0 13.3 10.7 24 24 24h182.6l-75.5 72.4c-9.7 9.3-9.9 24.8-.4 34.3l11 10.9c9.4 9.4 24.6 9.4 33.9 0L404.3 273c9.4-9.4 9.4-24.6 0-33.9L271.6 106.3c-9.4-9.4-24.6-9.4-33.9 0l-11 10.9c-9.5 9.6-9.3 25.1.4 34.4z"&gt;&lt;/path&gt;&lt;/svg&gt; [Next lecture](../02_MCMC/index.html)]]

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<style>
.logo {
  background-image: url("../assets/beamer/UCL-beamer.png");
  background-size: 14% 7%;
  background-repeat: no-repeat;
  position: absolute;
  top:  2.625%; /* 2.65%em */
  left: 85%;
  width: 100%;
  height: 100%;
  z-index: 0;
}
</style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.title-slide)' +
    // add additional classes to exclude here, e.g.
    // ':not(.inverse)' +
    ':not(.hide-logo)' +
    ':not(.thankyou-michelle)' +
    ':not(.thankyou-barney)'
  )
  .forEach(el => {
    el.innerHTML += '<div class="logo"></div>';
  });
</script>


<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
